[
  {
    "objectID": "02-DataWrangling.html",
    "href": "02-DataWrangling.html",
    "title": "Data Wrangling with R",
    "section": "",
    "text": "By the end of this session, students will be able to:\n\nExplain some benefits of learning R\nUnderstand the difference between R and RStudio\nNavigate RStudio\nDefine key R concepts and terminology.\nIdentify sources of documentation about R packages and functions\nApply commonly used tidyverse functions to a real data set\nBecoming familiar with a typical workflow for exploring and wrangling data."
  },
  {
    "objectID": "02-DataWrangling.html#learning-objectives",
    "href": "02-DataWrangling.html#learning-objectives",
    "title": "Data Wrangling with R",
    "section": "",
    "text": "By the end of this session, students will be able to:\n\nExplain some benefits of learning R\nUnderstand the difference between R and RStudio\nNavigate RStudio\nDefine key R concepts and terminology.\nIdentify sources of documentation about R packages and functions\nApply commonly used tidyverse functions to a real data set\nBecoming familiar with a typical workflow for exploring and wrangling data."
  },
  {
    "objectID": "02-DataWrangling.html#why-learn-r",
    "href": "02-DataWrangling.html#why-learn-r",
    "title": "Data Wrangling with R",
    "section": "Why learn R?",
    "text": "Why learn R?\n\nR is free, open-source, and cross-platform. Anyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs. Because R is open source and is supported by a large community of developers and users, there is a very large selection of third-party add-on packages which are freely available to extend R’s native capabilities.\nR code is great for reproducibility. Reproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis. R integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically.\nR relies on a series of written commands, not on remembering a succession of pointing and clicking. If you want to redo your analysis because you collected more data, you don’t have to remember which button you clicked in which order to obtain your results; you just have to run your script again.\nR is interdisciplinary and extensible With 10,000+ packages that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more.\nR works on data of all shapes and sizes. The skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won’t make much difference to you. R is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient. R can connect to spreadsheets, databases, and many other data formats, on your computer or on the web.\nR produces high-quality graphics. The plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data.\nR has a large and welcoming community. Thousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community. Questions which are backed up with short, reproducible code snippets are more likely to attract knowledgeable responses."
  },
  {
    "objectID": "02-DataWrangling.html#starting-out-in-r",
    "href": "02-DataWrangling.html#starting-out-in-r",
    "title": "Data Wrangling with R",
    "section": "Starting out in R",
    "text": "Starting out in R\nR is both a programming language and an interactive environment for data exploration and statistics.\nWorking with R is primarily text-based. The basic mode of use for R is that the user provides commands in the R language and then R computes and displays the result.\n\nDownloading, Installing and Running R\nDownload\nR can be downloaded from CRAN (The Comprehensive R Archive Network) for Windows, Linux, or Mac.\nInstall\nInstallation of R is like most software packages and you will be guided. Should you have any issues or need help you can refer to R Installation and Administration\nRunning\nR can be launched from your software or applications launcher or When working at a command line on UNIX or Windows, the command R can be used for starting the main R program in the form R\nYou will see a console similar to this appear:\n\n\n\n\n\n\n\n\n\nWhile it is possible to work solely through the console or using a command line interface, the ideal environment to work in R is RStudio.\n\n\nRStudio\nRStudio is a user interface for working with R. It is called an Integrated Development Environment (IDE): a piece of software that provides tools to make programming easier. RStudio acts as a sort of wrapper around the R language. You can use R without RStudio, but it’s much more limiting. RStudio makes it easier to import datasets, create and write scripts, and makes using R much more effective. RStudio is also free and open source. To function correctly, RStudio needs R and therefore both need to be installed on your computer.\nRStudio is divided into four “panes”. The placement of these panes and their content can be customized (see menu, Tools -&gt; Global Options -&gt; Pane Layout).\nThe Default Layout is:\n\nTop Left - Source: your scripts and documents\nBottom Left - Console: what R would look and be like without RStudio\nTop Right - Environment/History: look here to see what you have done\nBottom Right - Files and more: see the contents of the project/working directory here, like your Script.R file\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio Projects\nRStudio provides a useful feature called Projects which act like a container for your work. As you use R more, you will find it useful to make sure your files and environment for one real-world project are kept together and separate from other projects.\nLet’s create a new project now.\n\nGo to File &gt; New Project\nIn Create project from menu choose Existing Directory\nBrowse to Desktop &gt; Session01_DataWrangling\nSelect the check box that says Open in New Session\n\n\n\n\n\n\n\nFollow Along at Home\n\n\n\n\n\nPosit (RStudio) Cloud is a browser-based version of RStudio. It will allow you to use RStudio without needing to download anything to your computer. Posit Cloud automatically organizes things into Projects. You can also easily share your R projects with others.\nGet Started:\n\nCreate your free RStudio Cloud account at https://posit.cloud/plans/free.\nGo to the class project https://posit.cloud/content/8458222\nNote the text that marks this as a Temporary Copy. Select the Save a Permanent Copy button to begin working!"
  },
  {
    "objectID": "02-DataWrangling.html#r-scripts",
    "href": "02-DataWrangling.html#r-scripts",
    "title": "Data Wrangling with R",
    "section": "R Scripts",
    "text": "R Scripts\nA script is a text file in which you write your code. R scripts are generally recognized by the .R file extension. Scripts make it easy to re-run that code when you need to. In addition to code, your script can also have comments, which start with a # symbol. These comments make your script more human readable, but are ignored by the computer.\nTo get started in this lesson - open up the script in your RStudio Project called 01_DataWrangling.R"
  },
  {
    "objectID": "02-DataWrangling.html#welcome-to-the-tidyverse",
    "href": "02-DataWrangling.html#welcome-to-the-tidyverse",
    "title": "Data Wrangling with R",
    "section": "Welcome to the Tidyverse",
    "text": "Welcome to the Tidyverse\nIn this lesson, we will be using a group of packages which are part of what is known as the tidyverse - “an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.”1, developed by Hadley Wickham.\n\n\n\n\n\n\nWhat is a package?\n\n\n\nAs mentioned above, R is extensible and packages are the way to extend the base functionality of R. Each package is a collection of functions, code, data, and documentation. Packages are specialized to accomplish a particular set of tasks. Users can easily install packages from package repositories, such as the central repository CRAN (Comprehensive R Archive Network) and Bioconductor, an important source of bioinformatics packages.\nThe sheer number of R packages can seem overwhelming to a beginner and a common question we hear is, “But how do I know what package to use?”. One place is to start is to take a look at CRAN Task Views, which organizes packages by topic. You can also try an internet search like “How do I do X in R” and this will typically lead you to solutions that mention packages you need to accomplish the task.\nOne reason we are focusing on the tidyverse packages in this class is because they are so versatile and might be the only packages you need for much of what you want to do in R.\n\n\nThe tidyverse packages we will be using include:\n\nreadr for importing data into R\ndplyr for handling common data wrangling tasks for tabular data\ntidyr which enables you to swiftly convert between different data formats (long vs. wide) for plotting and analysis\nlubridate for working with dates\nggplot2 for visualizing data (we’ll explore this package in the next session).\n\nFor the full list of tidyverse packages and documentation visit tidyverse.org You can install these packages individually, or you can install the entire tidyverse in one go."
  },
  {
    "objectID": "02-DataWrangling.html#installing-and-loading-packages",
    "href": "02-DataWrangling.html#installing-and-loading-packages",
    "title": "Data Wrangling with R",
    "section": "Installing and loading packages",
    "text": "Installing and loading packages\nWhen you first install R on your computer, it comes with a set of built-in packages and functions collectively referred to as Base R. To add additional packages, you must first install that package, and then load it into your current session. If you are taking this workshop in person at the library, or using the class Posit Cloud project, the tidyverse has already been installed, so we just need to load it. You only need to install a package once on a system, but you will load it each time you start a new r session. If the package had not already been installed, we would install with a function called install.packages().\n\n#install tidyverse if you haven't yet\n#install.packages(\"tidyverse\")\n\n#load tidyverse\nlibrary(tidyverse)"
  },
  {
    "objectID": "02-DataWrangling.html#functions",
    "href": "02-DataWrangling.html#functions",
    "title": "Data Wrangling with R",
    "section": "Functions",
    "text": "Functions\ninstall.packages() and library() are two examples of functions. Functions are one of the most important components of R code. A function is like a canned script. It usually takes some inputs, called arguments inside the parentheses that follow the name of the function, performs one or more tasks, and often returns some kind of output. The library() function takes the name of the package to load as it’s argument.\nHow do you know what arguments a function takes? For that you need to turn to the documentation of a particular package, or from within RStudio you can look up a function with ?function-name. Let’s try it with the library() function.\n\n?library\n\nThis opens the help pane in the lower right corner of RStudio. The documentation provides you with all the arguments and any default values, along with explanations of the arguments. Here we see that the the library function has the argument package with no defaults."
  },
  {
    "objectID": "02-DataWrangling.html#what-is-tidy-data",
    "href": "02-DataWrangling.html#what-is-tidy-data",
    "title": "Data Wrangling with R",
    "section": "What is Tidy Data?",
    "text": "What is Tidy Data?\nThe tidyverse is so named from the concept of “tidy data”. Data is considered “tidy” if it follows three rules:\n\nEach column is a variable\nEach row is an observation\nEach cell is a single value2\n\nData “in the wild” often isn’t tidy, but the tidyverse packages can help you create and analyze tidy datasets.\n\n\n\n\n\ntidy data structure3"
  },
  {
    "objectID": "02-DataWrangling.html#the-data-for-this-lesson",
    "href": "02-DataWrangling.html#the-data-for-this-lesson",
    "title": "Data Wrangling with R",
    "section": "The Data for This Lesson",
    "text": "The Data for This Lesson\nFor this lesson we will be using data which comes from Project Tycho - an open data project from the University of Pittsburgh which provides standardized datasets on numerous diseases to aid global health research.\nThroughout this lesson, we will be using a dataset from Project Tycho featuring historical counts of measles cases in the U.S.. We want to clean and present this data in a way that makes it easy to see how measles cases fluctuated over time.\nA useful feature of Project Tycho data is their use of a common set of variables. Read more about their data format."
  },
  {
    "objectID": "02-DataWrangling.html#importing-data",
    "href": "02-DataWrangling.html#importing-data",
    "title": "Data Wrangling with R",
    "section": "Importing data",
    "text": "Importing data\nNow,that the tidyverse is loaded, we can use it to import some data into our RStudio session. We are using a function from the readr package called read_csv(). This function takes as an argument the path to where the file is located. Let’s start by reading in measles_us file in the /data folder.\n\nread_csv(\"data/measles_us.csv\")\n\nRows: 422051 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): ConditionName, PathogenName, CountryName, CountryISO, Admin1Name, ...\ndbl  (3): ConditionSNOMED, PartOfCumulativeCountSeries, CountValue\nlgl  (1): DiagnosisCertainty\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 422,051 × 15\n   ConditionName ConditionSNOMED PathogenName  CountryName CountryISO Admin1Name\n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;     \n 1 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 2 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 3 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 4 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 5 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 6 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 7 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 8 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 9 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n10 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n# ℹ 422,041 more rows\n# ℹ 9 more variables: Admin1ISO &lt;chr&gt;, Admin2Name &lt;chr&gt;, CityName &lt;chr&gt;,\n#   PeriodStartDate &lt;chr&gt;, PeriodEndDate &lt;chr&gt;,\n#   PartOfCumulativeCountSeries &lt;dbl&gt;, DiagnosisCertainty &lt;lgl&gt;,\n#   SourceName &lt;chr&gt;, CountValue &lt;dbl&gt;\n\n\nBut doing this just gives us a preview of the data in the console. To really use the data, we need to assign it to an object. An object is like a container for a numerical value, string, data set, image, and much more. Just about everything in R is an object. You might liken them to variables in other programming languages or in math. We create an object, by giving our data a name and use the assignment operator, which looks like an arrow &lt;-. You can manually type in the lesser than sign &lt; and hyphen -, or use the keyboard shortcut Alt + -.\nLet’s call our new object measles_us. Object names should be short and easy to understand. They can’t have spaces, so you’ll want to separate multiple words with a underscore, or by using camel case. Object names also need to start with a letter not a number, and it’s best to avoid using names of common functions.\n\nmeasles_us &lt;- read_csv(\"data/measles_us.csv\")\n\nWhen you create an object, it shows up in your environment pane (the upper right panel). If we check our environment pane, we should now see an object called measles_us.\nLet’s do the same for the states.csv file.\n\nstates &lt;- read_csv(file = \"data/states.csv\")\n\nRows: 50 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): name, division, region\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "02-DataWrangling.html#exploring-and-summarizing-data",
    "href": "02-DataWrangling.html#exploring-and-summarizing-data",
    "title": "Data Wrangling with R",
    "section": "Exploring and Summarizing data",
    "text": "Exploring and Summarizing data\nData wrangling, also known as data cleaning or data munging, involves preparing raw data for analysis by transforming it into a more useful format. This process includes detecting and correcting errors, handling missing values, and reorganizing data for analysis. Using the tidyverse, we can streamline these tasks efficiently. After importing the data, you’ll typically start by exploring it, identifying patterns, and making necessary adjustments to prepare it for visualization and further analysis. This foundational step ensures that your data is accurate, consistent, and ready for insightful exploration.\n\nVectors and Data Frames and Tibbles oh my!\nFirst, it’s important to understand the type of object we just created. In R, tabular data like you find in a spreadsheet is stored in a data frame, one of the fundamental data structures in R. A data frame is a rectangular, two-dimensional data structure. That is, it has both columns and rows. Data frames can store multiple data types, such as numeric, character, and logical data, also known as classes.\nA tibble is a tidyverse version of the standard R data frame. For our purposes, the differences are minor enough that we can generally use the terms interchangeably, but to be precise, we will be working with tibbles in this lesson. All tibbles are data frames, but not all data frames are tibbles.\nAnother important R data structure is a vector. A vector is a one-dimensional data structure. That is, it is simply a sequence of elements. A vector can have only one data type. Data frames are created from multiple vectors, that is, each column in a data frame is a vector of the same length.\n\n\nBase R functions for exploring data\nView() opens the data as a file in your documents pane.This is a good way to see the data in a familiar spreadsheet-like format.\n\nView(measles_us)\n\nUse summary() to look at each column and find the data type and interquartile range for numeric data.\n\nsummary(measles_us)\n\n\n\n\n\n\n\nMissing data\n\n\n\n\n\nSometimes we get data with a large number of missing values. It can be helpful to know where data is missing before attempting to do any further analysis. R uses NA to indicate missing values. We can use the function is.na() to test for the presence of NAs in our data.is.na() will return a vector of values TRUE or FALSE. TRUE if the value is NA, FALSE if it is not. When we examined our data with the View function, we might have noticed that the first several values in Admin2Name column are missing (NA). We might want to know how many missing values total are in that column.\n\nis.na(measles_us$Admin2Name)\n\nAfter running this code you should see TRUE printed out repeatedly in the console. R is running through that column and printing TRUE whenever it runs into a missing value. But this still does not help us get the total number of NAs. To do that we need to nest the above code in another function sum().\n\nsum(is.na(measles_us$Admin2Name))\n\n[1] 198104\n\n\nsum() treats each each TRUE as a 1 and each FALSE as a 0. In that column there are 198104 out of 422051\nBut, if you have a lot of variables (columns), it would be a pain to do this for each one. So instead we can use a similar function colSums\n\ncolSums(is.na(measles_us))\n\n              ConditionName             ConditionSNOMED \n                          0                           0 \n               PathogenName                 CountryName \n                          0                           0 \n                 CountryISO                  Admin1Name \n                          0                           0 \n                  Admin1ISO                  Admin2Name \n                          0                      198104 \n                   CityName             PeriodStartDate \n                     198104                           0 \n              PeriodEndDate PartOfCumulativeCountSeries \n                          0                           0 \n         DiagnosisCertainty                  SourceName \n                     422051                           0 \n                 CountValue \n                          0 \n\n\n\n\n\n\n\ntidyverse functions for exploring data\nThe glimpse() function which is part of the tidyverse package tibble, lets you see the column names and data types clearly.\n\nglimpse(measles_us)\n\ndistinct() returns the distinct rows in a tibble. It can be used on a column to return the distinct values in that column. The first argument you supply is the tibble object. Subsequent arguments include the variables you want to count.\n\ndistinct(measles_us, ConditionName)\n\n# A tibble: 1 × 1\n  ConditionName\n  &lt;chr&gt;        \n1 Measles      \n\n\n\ndistinct(measles_us, Admin1Name)\n\n# A tibble: 56 × 1\n   Admin1Name\n   &lt;chr&gt;     \n 1 WISCONSIN \n 2 OHIO      \n 3 MICHIGAN  \n 4 NEVADA    \n 5 NEW JERSEY\n 6 WASHINGTON\n 7 DELAWARE  \n 8 KENTUCKY  \n 9 WYOMING   \n10 INDIANA   \n# ℹ 46 more rows\n\n\ncount() is similar to distinct() but also returns the number of observations (i.e. rows) for each of those distinct values. The first argument you supply is the tibble object. Subsequent arguments include the variables you want to count.\n\n count(measles_us, Admin1Name) \n\n# A tibble: 56 × 2\n   Admin1Name               n\n   &lt;chr&gt;                &lt;int&gt;\n 1 ALABAMA               7458\n 2 ALASKA                1869\n 3 AMERICAN SAMOA         118\n 4 ARIZONA               4685\n 5 ARKANSAS              5643\n 6 CALIFORNIA           14354\n 7 COLORADO              8042\n 8 CONNECTICUT          10816\n 9 DELAWARE              4507\n10 DISTRICT OF COLUMBIA  5027\n# ℹ 46 more rows\n\n\n\n\n\n\n\n\nMake code flow with the pipe %&gt;%\n\n\n\nBefore we go any further - I want to introduce you to an important time-saving symbol in R called the pipe %&gt;% (CTRL + SHIFT + M). The pipe allows you to take the output of the left-hand expression and make it the input of the right-hand expression. It allows you to chain together multiple functions and avoid nesting. With the pipe, we can rewrite the above code as follows:\n\nmeasles_us %&gt;% \n  count(Admin1Name)\n\n# A tibble: 56 × 2\n   Admin1Name               n\n   &lt;chr&gt;                &lt;int&gt;\n 1 ALABAMA               7458\n 2 ALASKA                1869\n 3 AMERICAN SAMOA         118\n 4 ARIZONA               4685\n 5 ARKANSAS              5643\n 6 CALIFORNIA           14354\n 7 COLORADO              8042\n 8 CONNECTICUT          10816\n 9 DELAWARE              4507\n10 DISTRICT OF COLUMBIA  5027\n# ℹ 46 more rows\n\n\nIn many tidyverse functions, the first argument is the name of the data frame you’re applying the function to. So when you use the pipe, you’ll generally start a line of code with the name of a tibble. One benefit you might notice right away, is that when we use the pipe, RStudio will supply the column names which helps to reduce typing and typos.\n\n\n\n\nTry it Yourself!\n\n\n\n\n\n\nCHALLENGE\n\n\n\nNow let’s try exploring the states tibble in our environment\n\nUse glimpse() to inspect the columns and data types in the dataset.\nUse distinct() to find out the distinct values in the region column.\nUsing count(), find out how many states are in each region.\nUsing count(), find out how many states are in each region AND division. HINT: You can add additional column names to distinct() and count() to look at combinations of columns.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nglimpse(states)\nstates %&gt;% distinct(region)\nstates %&gt;% count(region)\nstates %&gt;% count(region, division)"
  },
  {
    "objectID": "02-DataWrangling.html#subsetting-data-with-select-and-filter",
    "href": "02-DataWrangling.html#subsetting-data-with-select-and-filter",
    "title": "Data Wrangling with R",
    "section": "Subsetting data with select() and filter()",
    "text": "Subsetting data with select() and filter()\nReal data sets can be quite large. So, once you’ve explored your data, you may want to start trimming it down to just the variables and conditions you’re interested in. In this section, we’ll look at two functions from the tidyverse package called dplyr: select() which lets you choose columns (variables) and filter() which lets you choose rows. (Note: dplyr is known for using easy to understand verbs for its function names.)\n\nselect()\nselect() lets you choose columns by name. The syntax of this function is similar to the the ones we’ve already learned count() and distinct(). We need to supply the function with the name of the tibble and the columns. This will create a new tibble with just those columns.\nAs with all tidyverse functions, we can use %&gt;% to make this easier.\n\nmeasles_us %&gt;% \nselect(Admin1Name, CountValue)\n\n# A tibble: 422,051 × 2\n   Admin1Name CountValue\n   &lt;chr&gt;           &lt;dbl&gt;\n 1 WISCONSIN          85\n 2 WISCONSIN         120\n 3 WISCONSIN          84\n 4 WISCONSIN         106\n 5 WISCONSIN          39\n 6 WISCONSIN          45\n 7 WISCONSIN          28\n 8 WISCONSIN         140\n 9 WISCONSIN          48\n10 WISCONSIN          85\n# ℹ 422,041 more rows\n\n\nIf you want to select several columns that are next to each other, you can use : to specify a range, rather than writing each name out separately.\n\nmeasles_us %&gt;% \nselect( ConditionName:Admin1ISO)\n\n# A tibble: 422,051 × 7\n   ConditionName ConditionSNOMED PathogenName  CountryName CountryISO Admin1Name\n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;     \n 1 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 2 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 3 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 4 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 5 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 6 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 7 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 8 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n 9 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n10 Measles              14189004 Measles virus UNITED STA… US         WISCONSIN \n# ℹ 422,041 more rows\n# ℹ 1 more variable: Admin1ISO &lt;chr&gt;\n\n\nNow, let’s think through which columns we want for our analysis and save this to a new object called measles_select. It’s always a good idea to create new objects when you make major changes to your data.\nFor this exercise, we want to look at trends in number of measles cases over time. To do that, we’ll need to keep our CountValue variable, as and the date variables (PeriodStartDate and PeriodEndDate), as well as the PartOfCumulativeCountSeries variable, which will help us understand how to use the dates (more on this later). The first five columns each have only one value. So it might be redundant to keep those, although if we were combining them with other Project Tycho datasets they could be useful. It might be interesting to get a state-level view of the data, so let’s keep Admin1Name. But we saw that there are a number of missing values in our Admin2Name and CityName variables, so they might not be very useful for our analysis.\n\nmeasles_select &lt;-\n  measles_us %&gt;%\n    select(\n     Admin1Name,\n     PeriodStartDate,\n     PeriodEndDate,\n     PartOfCumulativeCountSeries,\n     CountValue\n)\n\nSometimes when receive a data set or start working with data, you may find that the column names are overly long or not very descriptive or useful, and it may be necessary to rename them. For this, we can use the rename() function. Like naming objects, you should use a simple, descriptive, relatively short name without spaces for your column names. Let’s rename Admin1Name to State to make that more meaningful to us. rename() has the syntax rename(newColumnName = OldColumnName).\n\nmeasles_select &lt;-\n  measles_select %&gt;% \n    rename(state = Admin1Name)\n\nNote that in this case, we are overwriting our original object with the new name instead of creating a new one!\n\n\nfilter()\nWhile select() acts on columns, filter() acts on rows. filter() takes the name of the tibble and one or more logical conditions as arguments.\n\nmeasles_md &lt;- measles_select %&gt;% \n  filter(state == \"MARYLAND\")\n\nHere we are saying keep all the rows where the value in the state column is “MARYLAND”. Note the use of the double equals sign == versus the singular = sign. The double equal sign is a logical operator. The logical operators are:\n\n\n\noperator\nmeaning\n\n\n\n\n==\nexactly equal\n\n\n!=\nnot equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\nx|y\nx or y\n\n\nx&y\nx and y\n\n\n!x\nnot x\n\n\n\nNote that after running our code, our resulting tibble (our new object measles_md) has 7246 observations (rows) while our original tibble had 422051.\n\n\n\n\n\n\nWarning\n\n\n\nWhen matching strings you must be exact. R is case-sensitive. So state == \"Maryland\" or state == \"maryland\" would return 0 rows.\n\n\nYou can add additional conditions to filter by, separated other logical operators like &, &gt;, and &gt;.\nBelow we want just the rows for Maryland, and only include periods where the count was more than 500 reported cases. Note that while you need quotation marks around character data, you do not need them around numeric data.\n\nmeasles_select %&gt;%\n  filter(state == \"MARYLAND\" & CountValue &gt; 500)\n\n# A tibble: 328 × 5\n   state    PeriodStartDate PeriodEndDate PartOfCumulativeCountSeries CountValue\n   &lt;chr&gt;    &lt;chr&gt;           &lt;chr&gt;                               &lt;dbl&gt;      &lt;dbl&gt;\n 1 MARYLAND 1/29/1928       2/4/1928                                0        504\n 2 MARYLAND 2/5/1928        2/11/1928                               0        563\n 3 MARYLAND 2/12/1928       2/18/1928                               0        696\n 4 MARYLAND 2/19/1928       2/25/1928                               0        750\n 5 MARYLAND 2/26/1928       3/3/1928                                0       1012\n 6 MARYLAND 3/4/1928        3/10/1928                               0        951\n 7 MARYLAND 3/11/1928       3/17/1928                               0       1189\n 8 MARYLAND 3/18/1928       3/24/1928                               0       1163\n 9 MARYLAND 3/25/1928       3/31/1928                               0       1020\n10 MARYLAND 4/1/1928        4/7/1928                                0        753\n# ℹ 318 more rows\n\n\nHere, we joined together 2 conditions with the & logical operator. Then we piped that resulting tibble to count() which remember takes a tibble as its first argument.\nWhat if we wanted to filter our tibble to include just the 50 states and no territories? We sure would not have to write out an expression for each state, or even all the territories.\n\n# we can avoid verbose code like this with %in%\n\nmeasles_select %&gt;% \nfilter(state == \"MARYLAND\" & state == \"DELAWARE\" & state == \"Pennsylvania\")\n\n# A tibble: 0 × 5\n# ℹ 5 variables: state &lt;chr&gt;, PeriodStartDate &lt;chr&gt;, PeriodEndDate &lt;chr&gt;,\n#   PartOfCumulativeCountSeries &lt;dbl&gt;, CountValue &lt;dbl&gt;\n\n\nLuckily, We can filter based on a vector of values with the %in% operator (remember we can think of a vector as a column of data). So, we can write some code to filter our data based on list of state names in our states tibble.\n\nmeasles_states_only &lt;-\n  measles_select %&gt;% \n  filter(state %in% states$name)\n\nLet’s save this output to a new object measles_states_only. Notice how we now have fewer rows than we had in our measles_select object.\nWe could alternatively have used negation with the names of the values we specifically wanted to exclude.\n\nmeasles_states_only &lt;- measles_select %&gt;% \n  filter(!state %in% c(\"PUERTO RICO\", \"GUAM\", \"AMERICAN SAMOA\", \"NORTHERN MARIANA ISLANDS\", \"VIRGIN ISLANDS, U.S.\", \"DISTRICT OF COLUMBIA\"))\n\nGreat! Our dataset is really shaping up. Let’s also take a closer look at our date columns. If you look at the first several rows, it looks like each row of our dataset represents about a discrete week of measles case counts. But (as you can read in the Tycho data documentation) there are actually two date series in this dataset - non-cumulative and cumulative. Which series a row belongs to is noted by the PartofCumulativeCountSeries, which as the value 0 if a row is non-cumulative, and 1 if the row is part of a cumulative count.\nTo keep things consistent. Let’s filter our tibble so we only have the non-overlapping discrete weeks.\n\nmeasles_non_cumulative &lt;- \n  measles_states_only %&gt;% \n  filter(PartOfCumulativeCountSeries==0)\n\nOnce again, we have fewer rows than we started with.\n\n\nTry it Yourself\n\n\n\n\n\n\nCHALLENGE\n\n\n\n\nUse select() to create a new tibble with just the name and division columns from the states tibble. Assign this to an object called us_divisions.\nUse filter() to keep just the rows in the South Atlantic division of the us_divisions tibble. Assign this to an object called sa_division.\nUse filter() to keep just the rows in the measles_non_cumulative tibble where the state matches one of the states in the name column of the sa_division tibble and where the CountValue is greater than 1000. Assign this to an object called measles_sa.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nus_divisions &lt;- states %&gt;% select(name, division)\nsa_division &lt;- us_divisions %&gt;% filter(division == \"South Atlantic\")\nmeasles_sa &lt;- measles_non_cumulative %&gt;% filter(state %in% sa_division$name & CountValue &gt; 1000)\n\n\n\n\n\n\nNow let’s do some more with our date variables."
  },
  {
    "objectID": "02-DataWrangling.html#changing-and-creating-variables-with-mutate",
    "href": "02-DataWrangling.html#changing-and-creating-variables-with-mutate",
    "title": "Data Wrangling with R",
    "section": "Changing and creating variables with mutate()",
    "text": "Changing and creating variables with mutate()\nLet’s review the columns in our measles_states_only tibble\n\nglimpse(measles_non_cumulative)\n\nRows: 332,138\nColumns: 5\n$ state                       &lt;chr&gt; \"WISCONSIN\", \"WISCONSIN\", \"WISCONSIN\", \"WI…\n$ PeriodStartDate             &lt;chr&gt; \"11/20/1927\", \"11/27/1927\", \"12/4/1927\", \"…\n$ PeriodEndDate               &lt;chr&gt; \"11/26/1927\", \"12/3/1927\", \"12/10/1927\", \"…\n$ PartOfCumulativeCountSeries &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ CountValue                  &lt;dbl&gt; 85, 120, 84, 106, 39, 45, 28, 140, 48, 85,…\n\n\nWe can see from this that the dates are being interpreted as character data. We want R to recognize them as dates. We can create new variables and adjust existing variables with the mutate() function.\nmutate() takes as an argument the name and definition of the new column you’re creating. Note that if you use the same variable name as an existing variable name it overwrites that column. Otherwise, it will add a column to your tibble.\nTo change the variable to a date - we are using a date parsing function from another package called lubridate. mdy() takes a character string or number in month-day-year format (as we have here) and returns a formal date object in YYYY-MM-DD format. There are similar functions if the input date is in year-month-day ydm() or day-month-year dmy()\n\nmeasles_non_cumulative &lt;- measles_non_cumulative %&gt;% \nmutate(PeriodStartDate = mdy(PeriodStartDate),\n       PeriodEndDate = mdy(PeriodEndDate))\n\nNote that you can mutate multiple columns at a time, separating each new column definition with a comma.\nNow that R recognizes the date columns as Dates, we can do things like extract parts of the date, such as the year. Let’s create a separate Year column. Later we’ll be able to group our tibble by year for analysis.\n\nmeasles_year &lt;- \n  measles_non_cumulative %&gt;% \n  mutate(Year=year(PeriodStartDate))"
  },
  {
    "objectID": "02-DataWrangling.html#grouping-and-summarizing",
    "href": "02-DataWrangling.html#grouping-and-summarizing",
    "title": "Data Wrangling with R",
    "section": "Grouping and Summarizing",
    "text": "Grouping and Summarizing\nMany data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy through the use of the group_by() function.\ngroup_by() is often used together with summarize(), which collapses each group into a single-row summary of that group. group_by() takes as arguments the column names that contain the categorical variables for which you want to calculate the summary statistics.\nHow can we calculate the total number of measles cases for each year?\nFirst we need to group our data by year using our new Year column.\n\nyearly_count &lt;-\n  measles_year %&gt;%\n  group_by(Year)\n\nyearly_count\n\n# A tibble: 332,138 × 6\n# Groups:   Year [96]\n   state   PeriodStartDate PeriodEndDate PartOfCumulativeCoun…¹ CountValue  Year\n   &lt;chr&gt;   &lt;date&gt;          &lt;date&gt;                         &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 WISCON… 1927-11-20      1927-11-26                         0         85  1927\n 2 WISCON… 1927-11-27      1927-12-03                         0        120  1927\n 3 WISCON… 1927-12-04      1927-12-10                         0         84  1927\n 4 WISCON… 1927-12-18      1927-12-24                         0        106  1927\n 5 WISCON… 1927-12-25      1927-12-31                         0         39  1927\n 6 WISCON… 1928-01-01      1928-01-07                         0         45  1928\n 7 WISCON… 1928-01-08      1928-01-14                         0         28  1928\n 8 WISCON… 1928-01-15      1928-01-21                         0        140  1928\n 9 WISCON… 1928-01-22      1928-01-28                         0         48  1928\n10 WISCON… 1928-01-29      1928-02-04                         0         85  1928\n# ℹ 332,128 more rows\n# ℹ abbreviated name: ¹​PartOfCumulativeCountSeries\n\n\nWhen you inspect your new tibble, everything should look the same. Grouping prepares your data for summarize, but it does not do anything visually to the data.\nNow let’s trying summarizing that data. summarize() condenses the value of the group values to a single value per group. Like mutate(), we provide the function with the name of the new column that will hold the summary information. In this case, we will use the sum() function on the CountValue column and put this in a new column called TotalCount. Summarize will drop the columns that aren’t being used.\n\nyearly_count &lt;-\n  measles_year %&gt;%\n  group_by(Year) %&gt;%\n  summarise(TotalCount = sum(CountValue))\n\nyearly_count\n\n# A tibble: 96 × 2\n    Year TotalCount\n   &lt;dbl&gt;      &lt;dbl&gt;\n 1  1906       2345\n 2  1907      40199\n 3  1908      54471\n 4  1909      49802\n 5  1910      86984\n 6  1911      59171\n 7  1912      64773\n 8  1913     111431\n 9  1914      56440\n10  1915      93579\n# ℹ 86 more rows\n\n\nA more useful view might be to look for yearly totals of case counts by state. We can group by two variables, Year, and then State.\n\nyearly_count_state &lt;-\n  measles_year %&gt;%\n  group_by(Year, state) %&gt;%\n  summarise(TotalCount = sum(CountValue))\n\n`summarise()` has grouped output by 'Year'. You can override using the\n`.groups` argument.\n\nyearly_count_state\n\n# A tibble: 4,055 × 3\n# Groups:   Year [96]\n    Year state         TotalCount\n   &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;\n 1  1906 CALIFORNIA           224\n 2  1906 CONNECTICUT           23\n 3  1906 FLORIDA                4\n 4  1906 ILLINOIS             187\n 5  1906 INDIANA               20\n 6  1906 KENTUCKY               2\n 7  1906 MAINE                 26\n 8  1906 MASSACHUSETTS        282\n 9  1906 MICHIGAN             320\n10  1906 MISSOURI             274\n# ℹ 4,045 more rows\n\n\nNotice how the use of pipes really comes in handy here. It saved us from having to create and keep track of a number of intermediate objects."
  },
  {
    "objectID": "02-DataWrangling.html#sorting-datasets-with-arrange",
    "href": "02-DataWrangling.html#sorting-datasets-with-arrange",
    "title": "Data Wrangling with R",
    "section": "Sorting datasets with arrange()",
    "text": "Sorting datasets with arrange()\nWhich state in which year had the highest case count? To easily find out, we can use the function arrange(). One of the arguments must be the column you want to sort on.\n\nyearly_count_state %&gt;% arrange(TotalCount)\n\n# A tibble: 4,055 × 3\n# Groups:   Year [96]\n    Year state       TotalCount\n   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1  1925 NEVADA               0\n 2  1937 MISSISSIPPI          0\n 3  1938 MISSISSIPPI          0\n 4  1939 MISSISSIPPI          0\n 5  1940 MISSISSIPPI          0\n 6  1940 NEVADA               0\n 7  1941 MISSISSIPPI          0\n 8  1944 MISSISSIPPI          0\n 9  1945 MISSISSIPPI          0\n10  1906 TEXAS                1\n# ℹ 4,045 more rows\n\n\nBy default, arrange sorts in ascending order. To sort by descending order we use together with the desc() function.\n\nyearly_count_state %&gt;% arrange(desc(TotalCount))\n\n# A tibble: 4,055 × 3\n# Groups:   Year [96]\n    Year state        TotalCount\n   &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n 1  1938 PENNSYLVANIA     146467\n 2  1941 PENNSYLVANIA     137180\n 3  1938 ILLINOIS         127935\n 4  1942 CALIFORNIA       116180\n 5  1941 OHIO             114788\n 6  1935 MICHIGAN         111413\n 7  1941 NEW YORK         109663\n 8  1938 MICHIGAN         109041\n 9  1934 PENNSYLVANIA     107031\n10  1938 WISCONSIN        104450\n# ℹ 4,045 more rows"
  },
  {
    "objectID": "02-DataWrangling.html#joining-datasets",
    "href": "02-DataWrangling.html#joining-datasets",
    "title": "Data Wrangling with R",
    "section": "Joining Datasets",
    "text": "Joining Datasets\nOf course, looking at total counts in each state is not the most helpful metric without taking population into account. To rectify this, let’s try joining some historical population data with our measles data.\nFirst we need to import the population data4.\n\nhist_pop &lt;-\n  read_csv(\"data/Historical_Population_by_State.csv\")\n\nRows: 107 Columns: 52\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (52): DATE, ALASKA, ALABAMA, ARKANSAS, ARIZONA, CALIFORNIA, COLORADO, CO...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "02-DataWrangling.html#long-vs-wide-formats",
    "href": "02-DataWrangling.html#long-vs-wide-formats",
    "title": "Data Wrangling with R",
    "section": "Long vs Wide formats",
    "text": "Long vs Wide formats\nRemember that for data to be considered “tidy”, it should be in what is called “long” format. Each column is a variable, each row is an observation, and each cell is a value. Our state population data is in “wide” format, because State Name is being treated as a variable, when it is really a value. Wide data is often preferable for human-readability, but is less ideal for machine-readability. To be able to join this data to our measles dataset, it needs to have 3 columns - Year, State Name, and Population.\nWe will use the package tidyr and the function pivot_longer to convert our population data to a long format, thus making it easier to join with our measles data.\nEach column in our population dataset represents a state. To make it tidy we are going to reduce those to one column called State with the state names as the values of the column. We will then need to create a new column for population containing the current cell values. To remember that the population data is provided in 1000s of persons, we will call this new column pop1000.\npivot_longer() takes four principal arguments:\n\nthe data\ncols are the names of the columns we use to fill the new values variable (or to drop).\nthe names_to column variable we wish to create from the cols provided.\nthe values_to column variable we wish to create and fill with values associated with the cols provided.\n\n\nlibrary(tidyr)\nhist_pop_long &lt;- hist_pop %&gt;%\n  pivot_longer(ALASKA:WYOMING,\n               names_to = \"state\",\n               values_to = \"pop1000\")\n\n\nView(hist_pop_long)\n\nNow our two datasets have similar structures, a column of state names, a column of years, and a column of values. Let’s join these two datasets by the state and year columns. Note that if both sets have the same column names, you do not need to specify anything in the by argument. We use a left join here which preserves all the rows in our measles dataset and adds the matching rows from the population dataset.\n\nmeasles_joined&lt;- yearly_count_state %&gt;% \n  left_join(hist_pop_long, by=join_by(state, Year == DATE))\n\nmeasles_joined\n\n# A tibble: 4,055 × 4\n# Groups:   Year [96]\n    Year state         TotalCount pop1000\n   &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;\n 1  1906 CALIFORNIA           224    1976\n 2  1906 CONNECTICUT           23    1033\n 3  1906 FLORIDA                4     628\n 4  1906 ILLINOIS             187    5309\n 5  1906 INDIANA               20    2663\n 6  1906 KENTUCKY               2    2234\n 7  1906 MAINE                 26     729\n 8  1906 MASSACHUSETTS        282    3107\n 9  1906 MICHIGAN             320    2626\n10  1906 MISSOURI             274    3223\n# ℹ 4,045 more rows\n\n\n\n\n\n\n\n\nCHALLENGE\n\n\n\n\nUse mutate() to calculate the rate of measles per 100,000 persons (remember population is given in 1000s).\nTry joining measles_yearly_rates to states. What variable do you need to join by?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# 1. \nmeasles_yearly_rates &lt;-\n  measles_joined %&gt;% \n  mutate(epi_rate = (TotalCount / pop1000)*100)\n\n# 2. \nyearly_rates_joined &lt;- measles_yearly_rates %&gt;% \n  left_join(states, by = join_by(state == name))\n\n\n\n\n\n\nNow our data is ready to be visualized!"
  },
  {
    "objectID": "02-DataWrangling.html#footnotes",
    "href": "02-DataWrangling.html#footnotes",
    "title": "Data Wrangling with R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.tidyverse.org/↩︎\nread more about tidy data https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html↩︎\nimage from R for Data Science https://r4ds.had.co.nz/tidy-data.html#fig:tidy-structure↩︎\npopulation data retrieved from the FRED, the Federal Reserve Bank of St. Louis Economic Data, https://fred.stlouisfed.org/release/tables?rid=118&eid=259194↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "01-RBasics.html#learning-objectives",
    "href": "01-RBasics.html#learning-objectives",
    "title": "(PART*) Session I",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the value of learning R\nNavigate RStudio\nDefine terms: object, function, argument, package, vector, data frame.\nUse help documentation in RStudio."
  },
  {
    "objectID": "01-RBasics.html#why-learn-r",
    "href": "01-RBasics.html#why-learn-r",
    "title": "(PART*) Session I",
    "section": "Why learn R?",
    "text": "Why learn R?\n\nR is free, open-source, and cross-platform. Anyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs. Because R is open source and is supported by a large community of developers and users, there is a very large selection of third-party add-on packages which are freely available to extend R’s native capabilities.\nR code is great for reproducibility. Reproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis. R integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically.\nR relies on a series of written commands, not on remembering a succession of pointing and clicking. If you want to redo your analysis because you collected more data, you don’t have to remember which button you clicked in which order to obtain your results; you just have to run your script again.\nR is interdisciplinary and extensible With 10,000+ packages that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more.\nR works on data of all shapes and sizes. The skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won’t make much difference to you. R is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient. R can connect to spreadsheets, databases, and many other data formats, on your computer or on the web.\nR produces high-quality graphics. The plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data.\nR has a large and welcoming community. Thousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community. Questions which are backed up with short, reproducible code snippets are more likely to attract knowledgeable responses."
  },
  {
    "objectID": "01-RBasics.html#starting-out-in-r",
    "href": "01-RBasics.html#starting-out-in-r",
    "title": "(PART*) Session I",
    "section": "Starting out in R",
    "text": "Starting out in R\nR is both a programming language and an interactive environment for data exploration and statistics.\nWorking with R is primarily text-based. The basic mode of use for R is that the user provides commands in the R language and then R computes and displays the result.\n\nDownloading, Installing and Running R\nDownload\nR can be downloaded from CRAN (The Comprehensive R Archive Network) for Windows, Linux, or Mac.\nInstall\nInstallation of R is like most software packages and you will be guided. Should you have any issues or need help you can refer to R Installation and Administration\nRunning\nR can be launched from your software or applications launcher or When working at a command line on UNIX or Windows, the command R can be used for starting the main R program in the form R\nYou will see a console similar to this appear:\n\n\n\n\n\n\n\n\n\nWhile it is possible to work solely through the console or using a command line interface, the ideal environment to work in R is RStudio.\n\n\nRStudio\nRStudio is a user interface for working with R. It is called an Integrated Development Environment (IDE): a piece of software that provides tools to make programming easier. RStudio acts as a sort of wrapper around the R language. You can use R without RStudio, but it’s much more limiting. RStudio makes it easier to import datasets, create and write scripts, and makes using R much more effective. RStudio is also free and open source. To function correctly, RStudio needs R and therefore both need to be installed on your computer. But for this class we’ll be using a browser based version called RStudio Cloud (see directions in the RStudio Cloud section below.)\nRStudio is divided into four “panes”. The placement of these panes and their content can be customized (see menu, Tools -&gt; Global Options -&gt; Pane Layout).\nThe Default Layout is:\n\nTop Left - Source: your scripts and documents\nBottom Left - Console: what R would look and be like without RStudio\nTop Right - Environment/History: look here to see what you have done\nBottom Right - Files and more: see the contents of the project/working directory here, like your Script.R file\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio Cloud\nRStudio Cloud is a browser-based version of RStudio. It will allow you to use RStudio without needing to download anything to your computer. You can also easily share your R projects with others. While we recommend downloading RStudio for regular use, we will be using RStudio Cloud for these workshops so we can easily share files and packages with you.\nGet Started:\n\nCreate your free RStudio Cloud account at https://rstudio.cloud/plans/free.\nGo to the class project https://rstudio.cloud/content/4241048\nNote the text that marks this as a Temporary Copy. Select the Save a Permanent Copy button to begin working!"
  },
  {
    "objectID": "01-RBasics.html#using-this-book",
    "href": "01-RBasics.html#using-this-book",
    "title": "(PART*) Session I",
    "section": "Using this book",
    "text": "Using this book\nFor these instructions code will appear in the gray box as follows:\nfake code\nTo run the code you can copy and paste the code and run it in your RStudio session console at the prompt &gt; which looks like a greater than symbol.\n&gt; fake code\nThe code can also be added to an R Script to be run.\nWhen the code is run in RStudio the console prints out results like so:\n[1] Result\nIn this tutorial results from code will appear like so:\n## [1] Result"
  },
  {
    "objectID": "01-RBasics.html#working-in-the-console",
    "href": "01-RBasics.html#working-in-the-console",
    "title": "(PART*) Session I",
    "section": "Working in the Console",
    "text": "Working in the Console\nThe console is an interactive environment for RStudio, click on the “Console” pane, type 3 + 3 and press enter. R displays the result of the calculation.\n\n3 + 3\n\n[1] 6\n\n\n+ is called an operator. R has the operators you would expect for for basic mathematics:\nArithmetic operators\n\n\n\noperator\nmeaning\n\n\n\n\n+\nplus\n\n\n-\nminus\n\n\n*\ntimes\n\n\n/\ndivided by\n\n\n^\nexponent\n\n\n\nLogical Operators\n\n\n\noperator\nmeaning\n\n\n\n\n==\nexactly equal\n\n\n!=\nnot equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\nx|y\nx or y\n\n\nx&y\nx and y\n\n\n!x\nnot x\n\n\n\nSpaces can be used to make code easier to read.\n\n2 * 2 == 4\n\n[1] TRUE"
  },
  {
    "objectID": "01-RBasics.html#objects",
    "href": "01-RBasics.html#objects",
    "title": "(PART*) Session I",
    "section": "Objects",
    "text": "Objects\n\nCreating Objects\nWhen you have certain values, data, plots, etc that you want to work with You can create objects (make assignments) in R with the assignment operator &lt;-:\nAll R statements where you create objects, assignment statements, have the same form:\nobject_name &lt;- value\nWhen reading that code say “object name gets value” in your head.\n\nx &lt;- 3 * 4\n\nx\n\n[1] 12\n\n\nOnce you have an object you can do other calculations with it.\n\nx * x\n\n[1] 144\n\n\n\nObjects vs. Variables What are known as objects in R are known as variables in many other programming languages. Depending on the context, object and variable can have drastically different meanings. However, in this lesson, the two words are used synonymously. For more information see: https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects\n\n\n\nWorking with Objects\nThat last example was kind of abstract. So let’s look at a more practical example.\nLet’s do some calculations with the population of Maryland 1. First we can save the population number to an object. We will call it md_pop because that is short, descriptive, and easy to remember.\n\nmd_pop &lt;- 6165129\n\nWhat percentage of the Maryland population is over 18? According to the Census Bureau 2, 78% of the Maryland population is over 18. We can use that to calculate the number of adults in Maryland.\n\nmd_adult_pop &lt;- .78 * md_pop\n\nNext, we want to know what percentage of people in Maryland have been fully vaccinated for COVID-19. As of early July 2022 4.68 million people of all ages have been vaccinated in Maryland 3. So let’s create another object:\n\nmd_vax_pop &lt;- 4682799\n\nNow we can calculate the percentage of the Maryland population that is vaccinated.\n\npercent_vax &lt;- (md_vax_pop / md_pop) * 100\npercent_vax\n\n[1] 75.95622\n\n\nAs more people get vaccinated this can be updated. Let’s say later in year we have 4.9 million Marylanders who are fully vaccinated. We can re-assign the value of md_vax_pop\n\nmd_vax_pop &lt;- 4900000\n\nThen recalculate percent_vax\n\npercent_vax &lt;- (md_vax_pop / md_pop) * 100\npercent_vax\n\n[1] 79.47928\n\n\n\nTip You will make lots of assignments and &lt;- is a pain to type. Avoid the temptation to use =: it will work, but it will cause confusion later. Instead, use RStudio’s keyboard shortcut: Alt + - (the minus sign).\nNotice that RStudio automagically surrounds &lt;- with spaces, which is a good code formatting practice. Code is miserable to read on a good day, so giveyoureyesabreak and use spaces.\n\n\n\nNaming Objects\nThe name for objects must start with a letter, and can only contain letters, numbers, underscores (_)and periods (.). The name of the object should describe what is being assigned so they typically will be multiple words. One convention used is snake_case where lowercase words are separated with _. Another popular style is camelCase where compound words or phrases are written so that each word or abbreviation in the middle of the phrase begins with a capital letter, with no intervening spaces or punctuation and the first letter is lowercase.\n    thisIsCamelCase\n    some_use_snake_case\n    others.use.periods                  #avoid\n    Others_pRefer.to_RENOUNCEconvention #avoid\n\n\n\nChallenge\n\nQuestion  Earlier you created an object called md_adult_pop which used Census data to calculate the number of adults living in Maryland. According to the CDC4, 4040544 adults in Maryland have been fully vaccinated against COVID-19.\n\nAssign the number of fully vaccinated adults in Maryland to a new object.\nUse the new object together with md_adult_pop to calculate the percentage of adults in Maryland who are fully vaccinated. Save this to an object called md_adult_percent_vax."
  },
  {
    "objectID": "01-RBasics.html#saving-code-in-an-r-script",
    "href": "01-RBasics.html#saving-code-in-an-r-script",
    "title": "(PART*) Session I",
    "section": "Saving code in an R script",
    "text": "Saving code in an R script\nIt might seem like you could just as easily calculate the percentage of vaccinated Marylanders by hand. But what if you had to do it again and again, multiple times a day, for days on end? What if you had to make sure multiple people on your team could perform the same task?\nThis is where the real strength of R as a programming language comes in. You can save all the steps of your analysis to a script. This is especially powerful if you have long and complicated analyses. It is how R contributes to reproducible and open science.\nIf working in the RStudio Cloud project, open the file vax_count.R (or download the file if working locally). Here we have recorded the steps we just took. So let’s say you were training a new employee to run this very important analysis. Now all they have to do is input the new vaccination number, and run the script.\nThe usual workflow is to save your code in an R script (“.R file”). Go to “File/New File/R Script” to create a new R script. Code in your R script can be sent to the console by selecting it or placing the cursor on the correct line, and then pressing Control-Enter (Command-Enter on a Mac).\n\nTip Add comments to code, using lines starting with the # character. This makes it easier for others to follow what the code is doing (and also for us the next time we come back to it)."
  },
  {
    "objectID": "01-RBasics.html#setting-your-working-directory",
    "href": "01-RBasics.html#setting-your-working-directory",
    "title": "(PART*) Session I",
    "section": "Setting your Working Directory",
    "text": "Setting your Working Directory\nThe working directory is the location within which R points to the files system. RStudio sets up a default working directory, typically the home directory of the computer, which can be changed in the global options setting in RStudio.\nIn the code samples provided the data files are located in the R working directory, which can be found with the function getwd.\ngetwd() # get current working directory\nYou can select a different working directory with the function setwd(), and thus avoid entering the full path of the data files.\nsetwd(\"&lt;new path&gt;\")   # set working directory\nNote that the forward slash should be used as the path separator even on Windows platform.\nsetwd(\"C:/MyDoc\")\nAlternatively you can go to the working directory and set the working directory using the files panel and clicking the gear wheel for “more” within RStudio.\n\n\n\n\n\n\n\n\n\nOr by selecting the drop down list found in Tools(Windows) or Session(Mac) in the menu at the top of the RStudio window."
  },
  {
    "objectID": "01-RBasics.html#functions-and-their-arguments",
    "href": "01-RBasics.html#functions-and-their-arguments",
    "title": "(PART*) Session I",
    "section": "Functions and their arguments",
    "text": "Functions and their arguments\nFunctions are “canned scripts” that automate more complicated sets of commands including operations assignments, etc. Many functions are predefined, or can be made available by importing R packages (more on that later). A function usually gets one or more inputs called arguments. Functions often (but not always) return a value.\nA typical example would be the function round(). The input (the argument) must be a number, and the return value (in fact, the output) is that number rounded to the nearest whole number. Executing a function (‘running it’) is called calling the function. You can save the output of a function to an object. The format would look like:\n\nb &lt;- round(a)\n\nHere, the value of a is given to the round() function, the round() function rounds the number, and returns the value which is then assigned to the object b.\nThe return ‘value’ of a function need not be numerical (like that of sqrt()), and it also does not need to be a single item: it can be a set of things, or even a dataset. We’ll see that when we read data files into R.\nArguments can be anything, not only numbers or filenames, but also other objects. Exactly what each argument means differs per function, and must be looked up in the documentation (see below). Some functions take arguments which may either be specified by the user, or, if left out, take on a default value: these are called options. Options are typically used to alter the way the function operates, such as whether it ignores ‘bad values’, or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default.\nround() only needs one argument, a number, or object that is storing a numerical value.\n\nround(percent_vax)\n\n[1] 79\n\n\nHere, we’ve called round() on our percent_vax object and it returned 79. That’s because the default action of the function is to round to the nearest whole number. If we want more digits we can see how to do that by getting information about the round function. We can use args(round) or look at the help for this function using ?round.\n\nargs(round)\n\nfunction (x, digits = 0, ...) \nNULL\n\n\nWe see that if we want a different number of digits, we can type digits=2 or however many we want.\n\nround(percent_vax, digits = 2)\n\n[1] 79.48\n\n\nIf you provide the arguments in the exact same order as they are defined you don’t have to name them:\n\nround(percent_vax, 2)\n\n[1] 79.48\n\n\nAnd if you do name the arguments, you can switch their order:\n\nround(digits = 2, x = percent_vax)\n\n[1] 79.48\n\n\nIt’s good practice to put the non-optional arguments (like the number you’re rounding) first in your function call, and to specify the names of all optional arguments. If you don’t, someone reading your code might have to look up the definition of a function with unfamiliar arguments to understand what you’re doing.\n\nGetting Help\nIn the previous example we looked up the arguments to round() using args(round) alternatively we couldve looked at the help page for round() to find this out with ?round. To get help about a particular package or function you can access the help pane in RStudio and type its name in the search box.\n\n\n\n\n\n\n\n\n\nThe help() function and ? help operator in R provide access to the documentation pages for R functions, data sets, and other objects, both for packages in the standard R distribution and for contributed packages. To do so type as follows\nhelp({function})\nhelp(package = {package name})\n\n?{function}\n?\"{package name}\"\n\n\nChallenge: using functions\n\nQuestions \nLook at the documentation for the seq function. What does seq do? Give an example of using seq with either the by or length.out argument."
  },
  {
    "objectID": "01-RBasics.html#packages",
    "href": "01-RBasics.html#packages",
    "title": "(PART*) Session I",
    "section": "Packages",
    "text": "Packages\nWhile you can write your own functions, most functions you use will be part of a package. In R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. As of July 2018, there were over 14,000 packages available on the Comprehensive R Archive Network, or CRAN, the public clearing house for R packages. This huge variety of packages is one of the reasons that R is so successful.\nInstalling a package using RStudio requires selecting the Install Packages Button in the Files, Plots, Packages Pane\n\n\n\n\n\n\n\n\n\nIn the pop up box that results simply type the name of the package and check “install dependencies” and click Install\n\n\n\n\n\n\n\n\n\nIts also possible for you to install and load packages from the console. Always make sure to put the package name in quotes when installing and setting dependencies = True\n\ninstall.packages(\"tidyverse\", dependencies = TRUE)    \nlibrary(tidyverse)\n\nYou only need to install a package once, but you need to reload it every time you start a new session."
  },
  {
    "objectID": "01-RBasics.html#vectors",
    "href": "01-RBasics.html#vectors",
    "title": "(PART*) Session I",
    "section": "Vectors",
    "text": "Vectors\n\nWhat is a Vector?\n“Vector” means different things in different fields (mathematics, geometry, biology), but in R it is a fancy name for a collection of values. We call the individual values elements of the vector. It is one of the most common data structures you will work with in R.\nWe can make vectors with the function c( ), for example c(1,2,3). c means “combine”. R is obsessed with vectors, in R even single numbers are vectors of length one. Many things that can be done with a single number can also be done with a vector. For example arithmetic can be done on vectors as it can be on single numbers.\n\n\nWorking with Vectors\nLet’s say that we have a group of patients in our clinic. (See info in patients_list.txt in your project folder, or download the file.) We can store their names in a vector.\n\n    patients &lt;- c(\"Maria\", \"Jon\", \"Ali\", \"Luis\", \"Mei\" )\n\n    patients\n\n[1] \"Maria\" \"Jon\"   \"Ali\"   \"Luis\"  \"Mei\"  \n\n\nIf we later wanted to add a name, it’s easy to do so\n\npatients &lt;- c(patients, \"Emma\")\n\npatients\n\n[1] \"Maria\" \"Jon\"   \"Ali\"   \"Luis\"  \"Mei\"   \"Emma\" \n\n\nMaybe we also want to store the weights of these patients. Since these are their weights in pounds, we will call our object weight_lb\n\nweight_lb &lt;- c(122, 320, 217, 142, 174, 252)\n\nweight_lb\n\n[1] 122 320 217 142 174 252\n\n\nSo far, we have created vectors of two different data types: character and numeric.\nYou can do arithmetic with numeric vectors. For example, let’s convert the weight of our patients in lbs to the the weight in kilograms by multiplying each weight in lbs by 2.2.\nWe could do this one by one:\n\n122 / 2.2\n\n[1] 55.45455\n\n320 / 2.2\n\n[1] 145.4545\n\n217 / 2.2\n\n[1] 98.63636\n\n\netc.\nBut that would be a long and tedious process, especially if you had more than 6 patients.\nInstead, let’s divide the vector by 2.2 and save that to a new object. We will call this object weight_kg\n\nweight_kg &lt;- weight_lb / 2.2\n\n#you could also round the weight\nweight_kg &lt;- round((weight_lb / 2.2), digits = 2)\n\nweight_kg\n\n[1]  55.45 145.45  98.64  64.55  79.09 114.55\n\n\nWe could use the mean() function to find out the mean weight of patients at our clinic.\n\nmean(weight_lb)\n\n[1] 204.5\n\n\nYou will not be able to perform calculations with character vectors.\n\npatients + \"Sue\"\n\nError in patients + \"Sue\": non-numeric argument to binary operator\n\n\nRemember we used c() to add a value to our character vector.\n\nData Types  There are numerous data types. Some of the other most common data types you will encounter are numeric data, character data and logical data. Vectors of one data type only are called atomic vectors. Read more about vectors and data types in the book R for Data Science\n\nNow let’s try working with some logical data. Logical data is the valuesTRUE, FALSE, or NA\nWe want to record if our patients have been fully vaccinated. We will record this as TRUE if they have been, FALSE if they have not been, and NA if we do not have this information.\n\nvax_status &lt;- c(TRUE, TRUE, FALSE, NA, TRUE, FALSE)\n\nvax_status\n\n[1]  TRUE  TRUE FALSE    NA  TRUE FALSE\n\n\nAll vector types have a length property which you can determine with the length() function.\n\n    length(patients)\n\n[1] 6\n\n\nIts helpful to think of the length of a vector as the number of elements in the vector.\nYou can always find out the data type of your vector with the class() function.\n\nclass(patients)\n\n[1] \"character\"\n\nclass(weight_lb)\n\n[1] \"numeric\"\n\nclass(vax_status)\n\n[1] \"logical\"\n\n\n\n\nMissing Data\nR also has many tools to help with missing data, a very common occurrence.\nSuppose you tried to calculate the mean of a vector with some missing values (represented here with the logical NA. For example, what if we had failed to capture the weight of some of the patients at our clinic, so our weight vector looks as follows:\n\nmissing_wgt &lt;- c(122, NA, 217, NA, 174, 252)\n\nmean(missing_wgt)\n\n[1] NA\n\n\nThe missing values cause an error, and the mean cannot be correctly calculated.\nTo get around this, you can use the argument na.rm = TRUE. This says to remove the NA values before attempting to perform the calculation.\n\nmean(missing_wgt, na.rm = TRUE)\n\n[1] 191.25\n\n\nFor more on how to work with missing data, check out this Data Carpentry lesson\n\n\nMixing Data Types\nWe said above that vectors are supposed to have only one data type, but what happens if we mix multiple data types in one vector?\nSometimes the best way to understand R is to try some examples and see what it does.\n\nQuestions What will happen in each of these examples? Try running this code to see!\n\npatient &lt;- c(\"Maria\", 122, TRUE)\nname_weight &lt;- c(\"John\", 320, 145)\nweight_status &lt;- c(217, 99, FALSE)\n\nWhy do you think this happens?\n\nBecause vectors can only contain one type of data, R chooses a lowest common denominator type of vector, a type that can contain everything we are trying to put in it. A different language might stop with an error, but R tries to soldier on as best it can. A number can be represented as a character string, but a character string can not be represented as a number, so when we try to put both in the same vector R converts everything to a character string.\n\n\nIndexing and Subsetting vectors\nAccess elements of a vector with [ ], for example\n\n    patients[1]\n\n[1] \"Maria\"\n\n\n\n    patients[4]\n\n[1] \"Luis\"\n\n\nYou can also assign to a specific element of a vector. We realize that we misspelled the name of our patient John, so we can overwrite our old value by assigning a new name to that element in our vector.\n\n    patients[2] &lt;- \"John\"\n    patients\n\n[1] \"Maria\" \"John\"  \"Ali\"   \"Luis\"  \"Mei\"   \"Emma\" \n\n\nCan we use a vector to index another vector? Yes!\nLets say we want to know which of our patients have been vaccinated. We know the vaccination status because we have a vector named vax_status lets look at it\n\nvax_status\n\n[1]  TRUE  TRUE FALSE    NA  TRUE FALSE\n\n\nLooking at the output we see the index of vaccinated people is elements 1, 2, and 5. or where vax_status is TRUE in the output. We can use this numerical index to subset another from our vector patients which will give us a result that we’ll assign to a new object vax_patients.\n\n    vaxInd &lt;- c(1,2,5)\n    patients[vaxInd] # this line is saying patients[c(1,2,5)]\n\n[1] \"Maria\" \"John\"  \"Mei\"  \n\n\nNow we can assign this vector to an object vax_patients to quickly look at our vaccinated patients.\n\n    vax_patients &lt;- patients[vaxInd]\n    vax_patients\n\n[1] \"Maria\" \"John\"  \"Mei\"  \n\n\nThat was great! The problem with this approach is that if we’re in the real world and have a patient population of 1000 it will be really hard to go through our vax_status vector and see who has vax_status is TRUE. Fortunately there is a way to deal with this! Using conditional subsetting We could equivalently have written:\n\n    patients[vax_status == TRUE]\n\n[1] \"Maria\" \"John\"  NA      \"Mei\"  \n\n\nThis output keeps the NA’s in there and that is not helpful since we only want to know who is vaccinated. Instead we can add a second condition! This condition is awesome because we can now show off our skills of working with missing data!\n\npatients[vax_status == TRUE & !is.na(vax_status)]\n\n[1] \"Maria\" \"John\"  \"Mei\"  \n\n\nAnother thing we can do is to assign our logical expression to an object so we can index our vector using it but also index other data structures like data frames which we are about to learn about. To do this would be like this:\n\n# assign logical expression to an object\nare_vaccinated &lt;- vax_status == TRUE & !is.na(vax_status)\n# subset the vector according to the logical expression via using the object.\npatients[are_vaccinated]\n\n[1] \"Maria\" \"John\"  \"Mei\""
  },
  {
    "objectID": "01-RBasics.html#data-frames-tibbles-and-exploring-data",
    "href": "01-RBasics.html#data-frames-tibbles-and-exploring-data",
    "title": "(PART*) Session I",
    "section": "Data frames, Tibbles, and Exploring Data",
    "text": "Data frames, Tibbles, and Exploring Data\nData frames are another VIP data structure in R. While vectors are one dimensional data structures. Data frames are two dimensional (often called tabular or rectangular data). This is similar to data as you might be used to seeing it in a spreadsheet. You can think of a data frame as consisting of columns of vectors. As vectors,each column in a data frame is of one data type, but the data frame over all can hold multiple data types.\n\n\n\n\n\n\n\n\n\nA tibble is a particular class of data frame which is common in the tidyverse family of packages. Tibbles are useful for their printing properties and because they are less likely try to change the data type of columns on import (e.g. from character to factor).\n\nCreating data frames\nData frames are usually created by reading in a dataset using the read.table() or read.csv() which we will cover in our next session. However, data frames can also be created explicitly with the data.frame() function or they can be coerced from other types of objects like lists. Now that we know vectors form the columns of data frames, we can take the vectors we created for our patient data and combine them together in a data frame.\n\npatient_data &lt;- data.frame(patients, weight_lb, weight_kg, vax_status)\n\npatient_data\n\n  patients weight_lb weight_kg vax_status\n1    Maria       122     55.45       TRUE\n2     John       320    145.45       TRUE\n3      Ali       217     98.64      FALSE\n4     Luis       142     64.55         NA\n5      Mei       174     79.09       TRUE\n6     Emma       252    114.55      FALSE\n\n\n\n\nExploring data frames\nNow we will look at ways to explore the contents of a data frame. For this part of the lesson we will use an object variants, a data frame, that has been pre-loaded in your RStudio Cloud project as a .rds object, this is a binary Rdata file. To access this object locate /cloud/project/data/variants.rds in the file viewer and click on it. In the dialog box that pops up select “OK” In the next session you will learn how to load data in to R but for now we have done this for you so you can focus on learning about exploring data frames.\nThe variants object is a dataset that comes from a real world experiment in E. Coli, you can find out more about the study in the Tenaillon et al 2016 paper 5. The variants object is tabular version of a specialized genomics file type called a VCF file. VCF files are the output of a bioinformatics pipeline that starts with FASTQ files that come from a sequencer and ends with a VCF File. This pipeline typically happens outside of R and RStudio.\nYour initial instinct with working with this object is to want to see it in a familiar spreadsheet form. The View() function gives us a spreadsheet-like view of the data frame.\n\nView(variants)\n\nUsing the summary() function and, we can learn a lot about the variants data frame including some summary statistics. Let’s examine what this function can tell us:\n\n## get summary statistics on a data frame\n\nsummary(variants)\n\n  sample_id            CHROM                POS             ID         \n Length:801         Length:801         Min.   :   1521   Mode:logical  \n Class :character   Class :character   1st Qu.:1115970   NA's:801      \n Mode  :character   Mode  :character   Median :2290361                 \n                                       Mean   :2243682                 \n                                       3rd Qu.:3317082                 \n                                       Max.   :4629225                 \n                                                                       \n     REF                ALT                 QUAL          FILTER       \n Length:801         Length:801         Min.   :  4.385   Mode:logical  \n Class :character   Class :character   1st Qu.:139.000   NA's:801      \n Mode  :character   Mode  :character   Median :195.000                 \n                                       Mean   :172.276                 \n                                       3rd Qu.:225.000                 \n                                       Max.   :228.000                 \n                                                                       \n   INDEL              IDV              IMF               DP       \n Mode :logical   Min.   : 2.000   Min.   :0.5714   Min.   : 2.00  \n FALSE:700       1st Qu.: 7.000   1st Qu.:0.8824   1st Qu.: 7.00  \n TRUE :101       Median : 9.000   Median :1.0000   Median :10.00  \n                 Mean   : 9.396   Mean   :0.9219   Mean   :10.57  \n                 3rd Qu.:11.000   3rd Qu.:1.0000   3rd Qu.:13.00  \n                 Max.   :20.000   Max.   :1.0000   Max.   :79.00  \n                 NA's   :700      NA's   :700                     \n      VDB                 RPB              MQB              BQB        \n Min.   :0.0005387   Min.   :0.0000   Min.   :0.0000   Min.   :0.1153  \n 1st Qu.:0.2180410   1st Qu.:0.3776   1st Qu.:0.1070   1st Qu.:0.6963  \n Median :0.4827410   Median :0.8663   Median :0.2872   Median :0.8615  \n Mean   :0.4926291   Mean   :0.6970   Mean   :0.5330   Mean   :0.7784  \n 3rd Qu.:0.7598940   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :0.9997130   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                     NA's   :773      NA's   :773      NA's   :773     \n      MQSB              SGB               MQ0F           ICB         \n Min.   :0.01348   Min.   :-0.6931   Min.   :0.00000   Mode:logical  \n 1st Qu.:0.95494   1st Qu.:-0.6762   1st Qu.:0.00000   NA's:801      \n Median :1.00000   Median :-0.6620   Median :0.00000                 \n Mean   :0.96428   Mean   :-0.6444   Mean   :0.01127                 \n 3rd Qu.:1.00000   3rd Qu.:-0.6364   3rd Qu.:0.00000                 \n Max.   :1.01283   Max.   :-0.4536   Max.   :0.66667                 \n NA's   :48                                                          \n   HOB                AC          AN        DP4                  MQ       \n Mode:logical   Min.   :1   Min.   :1   Length:801         Min.   :10.00  \n NA's:801       1st Qu.:1   1st Qu.:1   Class :character   1st Qu.:60.00  \n                Median :1   Median :1   Mode  :character   Median :60.00  \n                Mean   :1   Mean   :1                      Mean   :58.19  \n                3rd Qu.:1   3rd Qu.:1                      3rd Qu.:60.00  \n                Max.   :1   Max.   :1                      Max.   :60.00  \n                                                                          \n    Indiv               gt_PL            gt_GT   gt_GT_alleles     \n Length:801         Min.   :   310   Min.   :1   Length:801        \n Class :character   1st Qu.:  1760   1st Qu.:1   Class :character  \n Mode  :character   Median :  2290   Median :1   Mode  :character  \n                    Mean   :  3392   Mean   :1                     \n                    3rd Qu.:  2550   3rd Qu.:1                     \n                    Max.   :255156   Max.   :1                     \n                                                                   \n\n\nThe original dataset had 29 variables, so we get 29 fields to look at in the summary() output that summarize the data for each variable. The QUAL, IMF, and VDB variables (and several others) are numerical data and so you get summary statistics on the min and max values for these columns, as well as mean, median, and interquartile ranges. Many of the other variables (e.g. sample_id) are treated as characters data (more on this in a bit).\nRunning the name variants of the data frame in the console alone shows the first 10 rows, print() with the n argument can be used to show more than the first 10 rows on the console. Keep in mind this allows you to only see the number of variables that fit in the width of your console. So wider console window allows to see more variables.\n\nprint(variants, n = 25)\n\nIf its the variable names you’re after you can do that with names() or colnames()\n\ncolnames(variants) # you could also use names()\n\n [1] \"sample_id\"     \"CHROM\"         \"POS\"           \"ID\"           \n [5] \"REF\"           \"ALT\"           \"QUAL\"          \"FILTER\"       \n [9] \"INDEL\"         \"IDV\"           \"IMF\"           \"DP\"           \n[13] \"VDB\"           \"RPB\"           \"MQB\"           \"BQB\"          \n[17] \"MQSB\"          \"SGB\"           \"MQ0F\"          \"ICB\"          \n[21] \"HOB\"           \"AC\"            \"AN\"            \"DP4\"          \n[25] \"MQ\"            \"Indiv\"         \"gt_PL\"         \"gt_GT\"        \n[29] \"gt_GT_alleles\"\n\n\nYou have access to details about the number of columns and rows also:\n\n# number of rows in variants\nnrow(variants)\n\n[1] 801\n\n# number of columns in variants\nncol(variants)\n\n[1] 29\n\n\nSubsetting data frames Similar to subsetting vectors using bracket syntax [], data frames can be subset using [row,column]. You can provide single dimensions to row and column or variations.\n\nvariants[4, 5]\n\n# A tibble: 1 × 1\n  REF     \n  &lt;chr&gt;   \n1 CTTTTTTT\n\n\nWhile the output of this subset is a single value the output is considered a data frame. This is typical of tibbles.\nYou can use a column name (in quotes and literally the name of the variable) to subset instead of a number (numerical index):\n\nvariants[4, \"REF\"]\n\n# A tibble: 1 × 1\n  REF     \n  &lt;chr&gt;   \n1 CTTTTTTT\n\n\nThe column or row may be omitted to retrieve the entire row or column.\n\nvariants[4,]\n\n# A tibble: 1 × 29\n  sample_id  CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SRR2584863 CP00… 433359 NA    CTTT… CTTT…    64 NA     TRUE     12     1    12\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\nvariants[, \"REF\"]\n\n# A tibble: 801 × 1\n   REF                             \n   &lt;chr&gt;                           \n 1 T                               \n 2 G                               \n 3 G                               \n 4 CTTTTTTT                        \n 5 CCGC                            \n 6 C                               \n 7 C                               \n 8 G                               \n 9 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\n10 AT                              \n# ℹ 791 more rows\n\n\nYou can use a vector to retrieve specific rows or columns you may want. This vector can be a named object or created on the spot and passed as an argument in the subsetting.\n\n# subset a range of rows using `colon :`\nvariants[35:45, ]\n\n# A tibble: 11 × 29\n   sample_id CHROM    POS ID    REF   ALT    QUAL FILTER INDEL   IDV   IMF    DP\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 SRR25848… CP00…  56613 NA    C     G       183 NA     FALSE    NA    NA    12\n 2 SRR25848… CP00…  62118 NA    A     G       225 NA     FALSE    NA    NA    19\n 3 SRR25848… CP00…  64042 NA    G     A       225 NA     FALSE    NA    NA    18\n 4 SRR25848… CP00…  78808 NA    C     T       225 NA     FALSE    NA    NA    23\n 5 SRR25848… CP00…  80113 NA    A     G       165 NA     FALSE    NA    NA     9\n 6 SRR25848… CP00…  81158 NA    A     C       225 NA     FALSE    NA    NA    13\n 7 SRR25848… CP00…  87462 NA    A     G       225 NA     FALSE    NA    NA    10\n 8 SRR25848… CP00…  94370 NA    A     G       225 NA     FALSE    NA    NA    11\n 9 SRR25848… CP00…  98286 NA    C     T       130 NA     FALSE    NA    NA     7\n10 SRR25848… CP00…  98404 NA    G     A       225 NA     FALSE    NA    NA    14\n11 SRR25848… CP00… 105581 NA    G     A       225 NA     FALSE    NA    NA    13\n# ℹ 17 more variables: VDB &lt;dbl&gt;, RPB &lt;dbl&gt;, MQB &lt;dbl&gt;, BQB &lt;dbl&gt;, MQSB &lt;dbl&gt;,\n#   SGB &lt;dbl&gt;, MQ0F &lt;dbl&gt;, ICB &lt;lgl&gt;, HOB &lt;lgl&gt;, AC &lt;dbl&gt;, AN &lt;dbl&gt;, DP4 &lt;chr&gt;,\n#   MQ &lt;dbl&gt;, Indiv &lt;chr&gt;, gt_PL &lt;dbl&gt;, gt_GT &lt;dbl&gt;, gt_GT_alleles &lt;chr&gt;\n\n\n\ncolumns_desired &lt;- c(1:3,6:7, 9)\nvariants[, columns_desired] # same as variants[,c(1:3,6:7, 9)]\n\n# A tibble: 801 × 6\n   sample_id  CHROM          POS ALT                                  QUAL INDEL\n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;                               &lt;dbl&gt; &lt;lgl&gt;\n 1 SRR2584863 CP000819.1    9972 G                                      91 FALSE\n 2 SRR2584863 CP000819.1  263235 T                                      85 FALSE\n 3 SRR2584863 CP000819.1  281923 T                                     217 FALSE\n 4 SRR2584863 CP000819.1  433359 CTTTTTTTT                              64 TRUE \n 5 SRR2584863 CP000819.1  473901 CCGCGC                                228 TRUE \n 6 SRR2584863 CP000819.1  648692 T                                     210 FALSE\n 7 SRR2584863 CP000819.1 1331794 A                                     178 FALSE\n 8 SRR2584863 CP000819.1 1733343 A                                     225 FALSE\n 9 SRR2584863 CP000819.1 2103887 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCC…    56 TRUE \n10 SRR2584863 CP000819.1 2333538 ATT                                   167 TRUE \n# ℹ 791 more rows\n\n\nYou might be interested in working with a new object that is just your subset from the main data frame. You can do this!\n\n# put the first three columns, column 6, column 7 and column 9 of variants into a new data frame called subset_variants\n\nsubset_variants &lt;- variants[,c(1:3,6:7, 9)]\n\nLets use str() to explore a bit more in depth how data frames work by looking at the “structure” of subset_variants.\n\nstr(subset_variants)\n\ntibble [801 × 6] (S3: tbl_df/tbl/data.frame)\n $ sample_id: chr [1:801] \"SRR2584863\" \"SRR2584863\" \"SRR2584863\" \"SRR2584863\" ...\n $ CHROM    : chr [1:801] \"CP000819.1\" \"CP000819.1\" \"CP000819.1\" \"CP000819.1\" ...\n $ POS      : num [1:801] 9972 263235 281923 433359 473901 ...\n $ ALT      : chr [1:801] \"G\" \"T\" \"T\" \"CTTTTTTTT\" ...\n $ QUAL     : num [1:801] 91 85 217 64 228 210 178 225 56 167 ...\n $ INDEL    : logi [1:801] FALSE FALSE FALSE TRUE TRUE FALSE ...\n\n\nOk, thats a lot to unpack! Some things to notice.\nIn the output of str() we see the object type tibble (S3: tbl_df/tbl/data.frame) is displayed in the first row along with its dimensions [801 × 6], in this case 801 observations (rows) and 6 variables (columns). Each variable (column) has a name (e.g. sample_id). This is followed by the object mode (e.g. chr, num, etc.). Notice that before each variable name there is a $ - lets look at this a little more since this is another way we can subset.\nSo far we have used numbers to retrieve columns from our data frames however you might prefer using the column name. To use a name we can use $ to retrieve columns. Occasionally it is also useful to use [[ ]] to retrieve columns, for example if the column name we want is stored in a variable.\n\n# extract the \"ALT\" column to a new object\n\nalt_alleles &lt;- subset_variants$ALT\n\nLets look at the first few elements of alt_alleles using head()\n\nhead(alt_alleles)\n\n[1] \"G\"         \"T\"         \"T\"         \"CTTTTTTTT\" \"CCGCGC\"    \"T\"        \n\n\nThis could have also been written using the double bracket notation\n\ndouble_bracket_ALT &lt;- subset_variants[[\"ALT\"]]\n# look at the first fiew rows of it\nhead(double_bracket_ALT)\n\n[1] \"G\"         \"T\"         \"T\"         \"CTTTTTTTT\" \"CCGCGC\"    \"T\"        \n\n\nTo get the ALT value for row 4 we could use a mix of $ and bracket [] subsetting.\n\nsubset_variants$ALT[4]\n\n[1] \"CTTTTTTTT\"\n\n\n(you may notice at this point were using bracket notation on a vector because the output of a $ subsetting is a vector, data frames are made up of columns of vectors!!!)\nLogical Subsetting(Indexing) We have already used logical indexing for subsetting a vector. Lets briefly look at an example of doing this with a data frame. Imagine that you want to have a data frame subset_variants_low_qual that is records from subset_variants that have very low quality scores.\n\nlow_qual_idX &lt;- subset_variants$QUAL &lt; 139\n\n# take a peak at the head of this\nhead(low_qual_idX)\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n# how many are TRUE?\nsum(low_qual_idX)\n\n[1] 200\n\n\nsum treats TRUE as 1 and FALSE as 0, so it tells us the number of TRUE elements in the vector (low_qual_idx).\nWe can use this logical vector to get the subset data frame subset_variants_low_qual that is only variants below the threshold we set.\n\nsubset_variants_low_qual &lt;- subset_variants[low_qual_idX, ]\n# take a look at the subset confirming with the first few values that they are below the threshold\nhead(subset_variants_low_qual)\n\n# A tibble: 6 × 6\n  sample_id  CHROM          POS ALT                                   QUAL INDEL\n  &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;                                &lt;dbl&gt; &lt;lgl&gt;\n1 SRR2584863 CP000819.1    9972 G                                     91   FALSE\n2 SRR2584863 CP000819.1  263235 T                                     85   FALSE\n3 SRR2584863 CP000819.1  433359 CTTTTTTTT                             64   TRUE \n4 SRR2584863 CP000819.1 2103887 ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCA…  56   TRUE \n5 SRR2584863 CP000819.1 2407766 C                                    104   FALSE\n6 SRR2584863 CP000819.1 2618472 T                                     31.9 FALSE\n\n\nIntroducing Factors Factors are the final major data type we will introduce in this R lessons. Factors can be thought of as vectors which are specialized for categorical data. Given R’s specialization for statistics, this make sense since categorical and continuous variables are usually treated differently. Sometimes you may want to have data treated as a factor, but in other cases, this may be undesirable.\nTo learn about factors we will work with the column subset_variants$ALT. First its important to know what type of object we’re working with using typeof() and then look at the first 15 elements of it using head():\n\ntypeof(subset_variants$ALT)\n\n[1] \"character\"\n\nhead(subset_variants$ALT, n = 15)\n\n [1] \"G\"                                                       \n [2] \"T\"                                                       \n [3] \"T\"                                                       \n [4] \"CTTTTTTTT\"                                               \n [5] \"CCGCGC\"                                                  \n [6] \"T\"                                                       \n [7] \"A\"                                                       \n [8] \"A\"                                                       \n [9] \"ACAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAGCCAG\"\n[10] \"ATT\"                                                     \n[11] \"C\"                                                       \n[12] \"C\"                                                       \n[13] \"T\"                                                       \n[14] \"T\"                                                       \n[15] \"A\"                                                       \n\n\nThere are 801 alleles (one for each row). To simplify, lets look at just the single-nuleotide alleles (SNPs). Before doing so we can confirm that SNPs are the most abundant using table(), we will also sort the output decreasing\n\nsort(table(subset_variants$ALT), decreasing = TRUE)[1:10]\n\n\n        A         T         G         C   GCCCCCC  GCCCCCCC  CAAAAAAA  TCCCCCCC \n      211       203       154       139         6         6         4         4 \nCAAAAAAAA  TGGGGGGG \n        3         3 \n\n\nWe can create a object snps_variants using another logical subsetting operator %in% that keeps rows corresponding to a vector of values in our case the values “A”, “C”, “G”, “T”.\n\nsnps_variants &lt;- subset_variants[subset_variants$ALT %in% c(\"A\", \"C\", \"G\", \"T\") ,]\n\nWhen we look at str() did this make our object a factor?\n\nstr(snps_variants$ALT)\n\n chr [1:707] \"G\" \"T\" \"T\" \"T\" \"A\" \"A\" \"C\" \"C\" \"T\" \"T\" \"A\" \"C\" \"A\" \"G\" \"C\" ...\n\n\nNO! The output says snps_variants$ALT is a chr and we promised you factors! To turn this or any other character vector that should be a categorical variable into a factor we can use the function factor() lets do this and look at its structure again.\n\nsnps_variants$ALT &lt;- factor(snps_variants$ALT)\nstr(snps_variants$ALT)\n\n Factor w/ 4 levels \"A\",\"C\",\"G\",\"T\": 3 4 4 4 1 1 2 2 4 4 ...\n\n\nWhat we get back are the categories (“A”,”C”,”G”,”T”) in our factor; these are called “Levels”. Levels are the different categories contained in a factor. For the sake of efficiency, R stores the content of a factor as a vector of integers, which an integer is assigned to each of the possible levels (a hold over from the old days when treating things as numbers saved space and processing time on the computer) By default, R will organize the levels in a factor in alphabetical order. So the first level in this factor is “A” and the final is “T”. We hope you have enjoyed this crash course in Factors! Now we will learn how to quickly explore our data with plots\n\n\nQuickly exploring data with plots\nFor very quick exploration of data, it’s sometimes useful to use the plotting functions in base R. These are installed by default with R and do not require any additional packages to be installed. They’re quick to type, straightforward to use in simple cases, and run very quickly.\nWe will pick up with factors with our first example. One of the most common uses for factors will be when you plot categorical values. For example, suppose we want to know how many of our snp_variants had each possible SNP we could generate a plot:\n\nplot(snps_variants$ALT)\n\n\n\n\n\n\n\n\nThis isn’t a particularly pretty example of a plot but it works!\nIf you recall, factors are ordered alphabetically. That might make sense, but categories (e.g., “red”, “blue”, “green”) often do not have an intrinsic order. What if we wanted to order our plot according to the numerical value (i.e., in order of SNP frequency)? We can enforce an order on our factors and plot again!:\n\nsnps_variants$ordered_factor_snps &lt;- factor(snps_variants$ALT, levels = names(sort(table(snps_variants$ALT))))\n\nLet’s deconstruct this from the inside out (you can try each of these commands to see why this works):\n\nWe create a table of factor_snps to get the frequency of each SNP: table(snps_variants$ALT)\nWe sort this table: sort(table(snps_variants$ALT)); use the decreasing = parameter for this function if you wanted to change from the default of FALSE\nUsing the names function gives us just the character names of the table sorted by frequencies:names(sort(table(snps_variants$ALT)))\nThe factor() function is what allows us to create a factor. We give it the snps_variants$ALT object as input, and use the levels= parameter to enforce the ordering of the levels.\n\nTaking a look at the plot we see it is reordered and very easy on the eyes!:\n\nplot(snps_variants$ordered_factor_snps)\n\n\n\n\n\n\n\n\nWow! Adenine is the most frequent SNP in this data\nIf you want to make a quick histogram you can pass a vector of values to hist(). To specify an approximate number of bins instead of the default you can add a breaks argument.\n\nhist(variants$QUAL)\n\n\n\n\n\n\n\n# get a clearer picture of the QUAL variable with more bins using `breaks=`\n\nhist(variants$QUAL, breaks = 20)\n\n\n\n\n\n\n\n\nWe have only covered 2 of the plots you can use to explore a dataset using Base R, we like these because they allow for quick checks of variables in the data. If you want to do anything beyond very simple plots, though, it’s generally better to switch to ggplot2 which you will learn in Session 3 of the CDABS summeR workshops!\nAt this point you can review the material or continue to some exercises we have put together for you. Congratulations you made it to the end!"
  },
  {
    "objectID": "01-RBasics.html#exercises",
    "href": "01-RBasics.html#exercises",
    "title": "(PART*) Session I",
    "section": "Exercises",
    "text": "Exercises\n\nOpen a new R script. Save it to your project folder. Use this script to record the answers to the exercises\nUse a comment to indicate the exercise number you are answering.\nCreate an object with the value of your name.\nCreate an object with the value of your age.\nDetermine the data type of each of the two objects you created above with the class() function.\nUse one of the strategies you learned in Getting Help to look up what the rm() function does. How would you use this on the objects you created in Questions 3 and 4?\nCreate a vector of the following names: Marcia, Jan, Cindy. Assign this to an object called brady_girls.\nCreate another vector of the following names: Greg, Peter, Bobby. Assign this to an object called brady_boys.\nCombine the brady_girls and brady_boys vectors together and assign to an object called brady_bunch.\nHow would you subset the 4th element in the brady_bunch vector?\nCall library(help = \"datasets\") to explore the various datasets contained in the datasets package. This package contains a number of example datasets you can use for practice.\nUse head() to look at the beginning of the dataset called ToothGrowth.\nHow would you find the number of columns and rows in ToothGrowth? How would you find summary information about this dataset?\nUse bracket notation to select the item in the 5th row and 2nd column of ToothGrowth.\nUse bracket notation to select the 5th through 10th rows of ToothGrowth.\nUse dollar sign notation to look at the len column of ToothGrowth.\nFind the mean of the len column.\nUse logical subsetting to save all the rows where the value in the supp column is OJ. Assign this to a new object."
  },
  {
    "objectID": "01-RBasics.html#footnotes",
    "href": "01-RBasics.html#footnotes",
    "title": "(PART*) Session I",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPopulation data from https://www.census.gov/quickfacts/MD↩︎\nPopulation data from https://www.census.gov/quickfacts/MD↩︎\nVaccination information from https://coronavirus.maryland.gov/#Vaccine↩︎\nCenters for Disease Control and Prevention. COVID Data Tracker. Atlanta, GA: US Department of Health and Human Services, CDC; 2022, July 06. https://covid.cdc.gov/covid-data-tracker↩︎\nTenaillon O, Barrick JE, Ribeck N, Deatherage DE, Blanchard JL, Dasgupta A, Wu GC, Wielgoss S, Cruveiller S, Médigue C, Schneider D, Lenski RE. Tempo and mode of genome evolution in a 50,000-generation experiment (2016) Nature. 536(7615): 165–170. Paper, Supplemental materials Data on NCBI SRA: https://trace.ncbi.nlm.nih.gov/Traces/sra/?study=SRP064605 Data on EMBL-EBI ENA: https://www.ebi.ac.uk/ena/data/view/PRJNA295606↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to R and the Tidyverse",
    "section": "",
    "text": "Session 1: Intro to R and RStudio This session will provide a solid foundation in working with R and RStudio and lay the groundwork to enable participants to explore more advanced topics in R programming. Topics covered include:\n• Navigating the RStudio interface, installing packages, getting help • Naming and working with objects • Using functions • Identifying R data types and structures • Working with scripts\nSession 2: Data Wrangling with R - Introduction to the Tidyverse This session will introduce the concept of “tidy” data, and the versatile collection of packages known as the Tidyverse. Participants will get hands-on experience wrangling real datasets. Topics covered include:\n• Importing data from external files • Subsetting and filtering data • Split-Apply-Combine analysis workflow • Creating variables • Joining data tables\nSession 3: Data Visualization in R with ggplot2 Learn how to use ggplot2, a robust Tidyverse package used to create high quality graphics for exploring and communicating your data. We will go beyond basic graphs and learn how to customize and annotate our graphs for more effective storytelling. Topics covered include:\n• Visualization best practices • Grammar of graphics - ggplot2 layers, aesthetics, and geoms • Choosing an effective graph type for your data • Customizing labels, axes, legends, and more • Choosing a color palette and themes\nSchedule\n\n\n\nDate\nTopic\n\n\n\n\nApril 10, 2025\nR Basics\n\n\nApril 17, 2025\nData Wrangling\n\n\nApril 24, 2025\nData Visualization"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Introduction to R and the Tidyverse",
    "section": "",
    "text": "Session 1: Intro to R and RStudio This session will provide a solid foundation in working with R and RStudio and lay the groundwork to enable participants to explore more advanced topics in R programming. Topics covered include:\n• Navigating the RStudio interface, installing packages, getting help • Naming and working with objects • Using functions • Identifying R data types and structures • Working with scripts\nSession 2: Data Wrangling with R - Introduction to the Tidyverse This session will introduce the concept of “tidy” data, and the versatile collection of packages known as the Tidyverse. Participants will get hands-on experience wrangling real datasets. Topics covered include:\n• Importing data from external files • Subsetting and filtering data • Split-Apply-Combine analysis workflow • Creating variables • Joining data tables\nSession 3: Data Visualization in R with ggplot2 Learn how to use ggplot2, a robust Tidyverse package used to create high quality graphics for exploring and communicating your data. We will go beyond basic graphs and learn how to customize and annotate our graphs for more effective storytelling. Topics covered include:\n• Visualization best practices • Grammar of graphics - ggplot2 layers, aesthetics, and geoms • Choosing an effective graph type for your data • Customizing labels, axes, legends, and more • Choosing a color palette and themes\nSchedule\n\n\n\nDate\nTopic\n\n\n\n\nApril 10, 2025\nR Basics\n\n\nApril 17, 2025\nData Wrangling\n\n\nApril 24, 2025\nData Visualization"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Introduction to R and the Tidyverse",
    "section": "Acknowledgements",
    "text": "Acknowledgements"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Introduction to R and the Tidyverse",
    "section": "License",
    "text": "License\nThis work is licensed under a Creative Commons Attribution 4.0 International License (CC BY)"
  },
  {
    "objectID": "03-DataVisualization.html",
    "href": "03-DataVisualization.html",
    "title": "Data Visualization with ggplot2",
    "section": "",
    "text": "Become familiar with the components of a ggplot2 graph (i.e. the grammar of graphics)\nUse best practices for different graph types\nUnderstand how to use visualizations to tell a data story"
  },
  {
    "objectID": "03-DataVisualization.html#learning-objectives",
    "href": "03-DataVisualization.html#learning-objectives",
    "title": "Data Visualization with ggplot2",
    "section": "",
    "text": "Become familiar with the components of a ggplot2 graph (i.e. the grammar of graphics)\nUse best practices for different graph types\nUnderstand how to use visualizations to tell a data story"
  },
  {
    "objectID": "03-DataVisualization.html#getting-set-up",
    "href": "03-DataVisualization.html#getting-set-up",
    "title": "Data Visualization with ggplot2",
    "section": "Getting set up",
    "text": "Getting set up\n\nGo to File &gt; New Project\nIn Create project from menu choose Existing Directory\nBrowse to Desktop &gt; Session02_DataVisualization\nSelect the check box that says Open in New Session\nOpen the companion script called 02-DataVisualization.R\nUse the library() function to load the tidyverse, viridis, and usmap packages.\nUse the read_csv() function to import the yearly_rates_joined and the region_summary csv files.\n\n\n\n\n\n\n\nFollow Along at Home\n\n\n\n\n\nPosit (RStudio) Cloud is a browser-based version of RStudio. It will allow you to use RStudio without needing to download anything to your computer. Posit Cloud automatically organizes things into Projects. You can also easily share your R projects with others.\nGet Started:\n\nCreate your free RStudio Cloud account at https://posit.cloud/plans/free if you haven’t already.\nGo to the class project https://posit.cloud/content/8458074\nNote the text that marks this as a Temporary Copy. Select the Save a Permanent Copy button to begin working!\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(usmap)\n\nyearly_rates_joined &lt;- read_csv(\"data/yearly_rates_joined.csv\")\n\nregion_summary &lt;- read_csv(\"data/region_summary.csv\")"
  },
  {
    "objectID": "03-DataVisualization.html#why-data-visualization",
    "href": "03-DataVisualization.html#why-data-visualization",
    "title": "Data Visualization with ggplot2",
    "section": "Why Data Visualization?",
    "text": "Why Data Visualization?\nVisualization is an important process which can help us explore, understand, analyze, and communicate about data. Visualizations, including many kinds of graphs, charts, maps, animations, and infographics, can be far more effective at quickly communicating important points than raw numbers alone. But visualizations also have the power to mislead. And so throughout this class, we’ll be covering some good data visualization practices. Slides accompanying this section can be found here: https://osf.io/yk5bx1"
  },
  {
    "objectID": "03-DataVisualization.html#the-data-for-this-lesson",
    "href": "03-DataVisualization.html#the-data-for-this-lesson",
    "title": "Data Visualization with ggplot2",
    "section": "The Data for This Lesson",
    "text": "The Data for This Lesson\nIn this lesson, we will continue to use the measles data we were working with in the Data Wrangling lesson. By the end of that lesson, we had joined our measles tibble with another tibble of population data. This enabled us to calculate the incidence rate of measles in each state and each year. We also combined that data with the states tibble so we could look at regional and division trends as well."
  },
  {
    "objectID": "03-DataVisualization.html#ggplot2-basics",
    "href": "03-DataVisualization.html#ggplot2-basics",
    "title": "Data Visualization with ggplot2",
    "section": "ggplot2 Basics",
    "text": "ggplot2 Basics\nNext, we will learn about ggplot2 - a tidyverse package for visualizing data. It is a powerful and flexible R package that allows you to create fully customizable, publication quality graphics. The gg in ggplot2 stands for grammar of graphics. The grammar of graphics is the underlying philosophy of the package. It focuses on creating graphics in layers. Start with the data – map the data to the axes and to aesthetic qualities like size, shape, and color and geometries like dots, lines, and polygons. Further refine the appearance of your plot by adjusting scales and legends, labels, coordinate systems, and adding annotations.\nAll ggplot2 graphs start with the same basic template:\n&lt;DATA&gt; %&gt;%\n    ggplot(aes(&lt;MAPPINGS&gt;)) +\n    &lt;GEOM_FUNCTION&gt;() +\n    &lt;Additional GEOMS, SCALES, THEMES, etc. . . &gt;\n\nAll graphs start with the ggplot function and the data. We’ll use the pipe to pipe the data to the function.\n\nregion_summary %&gt;% \n  ggplot()\n\n\n\n\n\n\n\n\nWe see that even this initializes the plot area of RStudio.\nNext, we define a mapping (using the aesthetic, or aes(), function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g. as x/y positions or characteristics such as size, shape, color, etc. Here we will say that the x axis should contain the affiliation variable. Note how the x-axis populates with some numbers and tick marks.\n\nregion_summary %&gt;%\n  ggplot(aes(x=region, y=avg_rate))\n\n\n\n\n\n\n\n\nNext we need to add ‘geoms’ – graphical representations of the data in the plot (points, lines, bars). ggplot2 offers many different geoms for common graph types. To add a geom to the plot use the + operator.\n\nregion_summary %&gt;%\n  ggplot(aes(x=region, y=avg_rate)) +\n           geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nIf you want the y axis to display something other than count, you need to make a couple of small adjustments. First - specify the y variable in the aes() function, and change the stat argument from it’s default of “count” to “identity” This tells it to base the y axis on the specified variable."
  },
  {
    "objectID": "03-DataVisualization.html#setting-vs-mapping-aesthetics",
    "href": "03-DataVisualization.html#setting-vs-mapping-aesthetics",
    "title": "Data Visualization with ggplot2",
    "section": "Setting vs mapping aesthetics",
    "text": "Setting vs mapping aesthetics\nWhen working with ggplot2, it’s important to understand the difference between setting aesthetic properties and mapping them. All geoms have certain visual attributes that can be modified. Polygons like bars, have the properties fill and color. You can change the inside color of a bar with fill, and the border with color. We can modify the defaults with the fill and color arguments in the geom_bar() layer. (I’ve also increased the linewidth to make it easier to see the border color)\n\nregion_summary %&gt;%\n  ggplot(aes(x=region, y=avg_rate)) +\n           geom_bar(stat = \"identity\",\n                    fill=\"blue\",\n                    color=\"purple\",\n                    linewidth=1.5,\n                    width = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHow did we know the color names “blue” and “purple” would work in the code above? R has 657 (!!) built in color names. You can see them by calling the function colors(). You can also specify colors using rgb and hexadecimal codes.\n\n\nNow we have manually set a value for the fill and color. To create our initial graph, we used the mapping argument and the aes() function to map the x axis to the region variable. Watch what happens if we map the fill property to the region variable as well.\n\nregion_summary %&gt;%\n  ggplot(aes(x=region, y=avg_rate, fill=region)) +\n           geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nAs we’ll see later in this lesson, mapping a variable to an aesthetic will be especially helpful when we have a third variable to display.\n\n\n\n\n\n\nNote\n\n\n\nWhen you map an aesthetic with aes() in the ggplot() function it is inherited by all subsequent layers. When you map in a geom_*() function it is applied only to that layer."
  },
  {
    "objectID": "03-DataVisualization.html#telling-a-data-story",
    "href": "03-DataVisualization.html#telling-a-data-story",
    "title": "Data Visualization with ggplot2",
    "section": "Telling a data story",
    "text": "Telling a data story\nNow let’s start using ggplot2 to help us answer our research question - how did the introduction of the vaccine affect measles rates in the country? We’ll do this with a line graph, which is useful for showing change over time.\nFirst, we need to use our **dplyr** skills to summarize the data.\n\nyearly_count &lt;- yearly_rates_joined %&gt;% \n  group_by(Year) %&gt;% \n  summarize(TotalCount = sum(TotalCount))\n\nWe pipe to ggplot() and assign Year to the x-axis and TotalCount to the y-axis with the aes() function. The canvas and axes are ready.\n\nyearly_count %&gt;% \n  ggplot(aes(x=Year, y=TotalCount))\n\n\n\n\n\n\n\n\nNow we can add a geom layer to add our line. Let’s also be sure to save our work to an object.\n\nyearly_count %&gt;% \n  ggplot(aes(x=Year, y=TotalCount)) + \n  geom_line()\n\n\n\n\n\n\n\n\nIt might be nice to see where each data point falls on the line. To do this we can add another geometry layer.\n\nyearly_count %&gt;% \n  ggplot(aes(x=Year, y=TotalCount)) + \n  geom_line() +\n  geom_point()\n\n\n\n\n\n\n\n\nThere are many ways to customize your plot, like changing the color or line type, adding labels and annotations. One thing that would make our graph easier to read is tick marks at each decade on the x-axis. There are a number of functions in ggplot2 for altering the scale. We want to alter the x-axis scale, which holds continuous data, so we can use the scale_x_continuous() function. Note that when you start to write the name of the function, RStudio will supply you with other similarly named functions.\nscale_x_continuous() has an argument called breaks which allows you to alter where the axis tick marks occur. We can use that together with seq() to say put a tick mark every 10 places between 1900 and 2000.\n\nyearly_count  %&gt;% \n  ggplot(aes(x=Year, y=TotalCount)) + \n  geom_line() +\n  geom_point() + \n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10))\n\n\n\n\n\n\n\n\nNow we can move beyond basic exploration and start to use our graph to analyze and tell stories about our data. One important trend we might notice, is the sharp decrease in cases in the 1960s. The measles vaccine was introduced in 1963. We can use our visualization to tell the story of the vaccine’s impact.\nLet’s drop a reference line at 1963 to clearly indicate on the graph when the vaccine was introduced. To do this we add a geom_vline() and the annotate() function. There are multiple ways of adding lines and text to a plot, but these will serve us well for this case. Note that you can change features of lines such as color, type, and size. We can supply coordinates to annotate() to position the annotation where we want.\n\nyearly_count %&gt;% \n  ggplot(aes(x=Year, y=TotalCount)) + \n  geom_line() +\n  geom_point() + \n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10)) +\n  geom_vline(xintercept = 1963, color = \"red\", linetype= \"dashed\") +\n  annotate(geom = \"label\", x=1963, y=800000, label=\"1963: vaccine introduced\")\n\n\n\n\n\n\n\n\nFinally, let’s add a title and axis labels to our plot with the labs() function. Note that axis labels will automatically be supplied from the column names, but you can use this function to override those defaults.\n\nyearly_count_line &lt;- yearly_count %&gt;% \n  ggplot(aes(x=Year, y=TotalCount)) + \n  geom_line() +\n  geom_point() + \n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10)) +\n  geom_vline(xintercept = 1963, color = \"red\", linetype= \"dashed\") +\n  annotate(geom = \"label\", x=1963, y=800000, label=\"1963: vaccine introduced\") +\n  labs(title = \"Measles Cases Decrease After Vaccine Introduced\", x = \"Year\", y = \"Total Measles Case Count\")\n\nNow, we have a pretty nice looking graph. Finally, let’s save our plot to a png file, so we can share it or put it in reports. To do this we use the function called ggsave().\n\nggsave(\"figures/yearly_measles_count.png\", plot = yearly_count_line)"
  },
  {
    "objectID": "03-DataVisualization.html#working-with-three-variables",
    "href": "03-DataVisualization.html#working-with-three-variables",
    "title": "Data Visualization with ggplot2",
    "section": "Working with Three Variables",
    "text": "Working with Three Variables\nIf we have different groups in our data, we might want to use the graph to compare them. Let’s create another line graph with a line for each region. Since the regions are different sizes, let’s compare the average rate instead of the total count.\nFirst, let’s summarize our data\n\nregional_rates &lt;- yearly_rates_joined %&gt;% \ngroup_by(Year, region) %&gt;% \nsummarize(avg_rate = mean(epi_rate, na.rm=TRUE))\n\n\nregional_rates %&gt;% \n  ggplot(aes(x=Year, y=avg_rate, group=region, color=region)) + \n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with color palettes\n\n\n\nWhile ggplot comes with a default color palette, there are numerous other palettes out there you can use, such as:\n\nRColorBrewer\nviridis\nggthemes\nggsci\nwesanderson\n\n\n\nLet’s try applying a viridis palette. viridis was designed to be especially robust for many forms of color-blindness. It is also meant to print well in grey scale.\nTo do this, we need add another scale_ function. This time scale_color_viridis().\n\nregional_rates %&gt;% \n  ggplot(aes(x=Year, y=avg_rate, group=region, color=region)) + \n  geom_line(linewidth=1) +\n  scale_color_viridis(discrete=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLearn more from the viridis documentation\n\n\nLet’s adjust tick marks and add labels again\n\nregional_rates %&gt;% \n  ggplot(aes(x=Year, y=avg_rate, group=region, color=region)) + \n  geom_line(linewidth=1) +\n  scale_color_viridis(discrete=TRUE)  +\n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10)) +\n  labs(x=\"\", y= \"Incidence Rate of measles \\n per 100,000 persons\", color=\"Region\")"
  },
  {
    "objectID": "03-DataVisualization.html#changing-the-theme",
    "href": "03-DataVisualization.html#changing-the-theme",
    "title": "Data Visualization with ggplot2",
    "section": "Changing the theme",
    "text": "Changing the theme\nThe theme of a ggplot2 graph controls the overall look and all non-data elements of the plot. There are several built-in themes which can be applied as another layer. Start typing theme_ in RStudio to see a list of themes. You can also use the theme() function to modify aspects of an existing theme. Here we apply theme_classic() which removes the grid lines and grey background of the default theme.\n\nregional_rates %&gt;% \n  ggplot(aes(x=Year, y=avg_rate, group=region, color=region)) + \n  geom_line(linewidth=1) +\n  scale_color_viridis(discrete=TRUE)  +\n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10)) +\n  labs(title = \"Measles Cases in the 20th Century\", x=\"\", y= \"Average rate\\nper 100,000\", color=\"Region\") +\ntheme_classic()\n\n\n\n\n\n\n\n\nIn addition to setting an overall theme, we can tinker with individual elements of a theme with the theme() function. Check out the ggplot2 documentation for all the elements that can be adjusted. Here we are going to make an adjustment to the y axis label. It’s good practice to make as much of your text horizontal as possible for ease of reading.\n\nregional_rates %&gt;% \n  ggplot(aes(x=Year, y=avg_rate, group=region, color=region)) + \n  geom_line(linewidth=1) +\n  scale_color_viridis(discrete=TRUE)  +\n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10)) +\n  labs(title = \"Measles Cases in the 20th Century\", x=\"\", y= \"Average rate\\nper 100,000\", color=\"Region\") +\n  theme_classic() +\n  theme(axis.title.y = element_text(angle=0, vjust = 0.5, hjust = 0.5))"
  },
  {
    "objectID": "03-DataVisualization.html#faceting-and-small-multiples",
    "href": "03-DataVisualization.html#faceting-and-small-multiples",
    "title": "Data Visualization with ggplot2",
    "section": "Faceting and Small Multiples",
    "text": "Faceting and Small Multiples\nEven with the adjustments we made, it can be difficult to understand a graph with too much data. Even with just five lines it can be hard to see what’s happening. A good practice is to break out each group into individual graphs called small multiples or facets.\n\nregional_rates %&gt;% \n  ggplot(aes(x=Year, y=avg_rate, group=region, color=region)) + \n  geom_line(linewidth=1) +\n  scale_color_viridis(discrete=TRUE)  +\n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10)) +\n  labs(title = \"Measles Cases in the 20th Century\", x=\"\", y= \"Average rate\\nper 100,000\", color=\"Region\") +\n  facet_wrap(~region, nrow=2) + \n  theme_classic() +\n  theme(axis.title.y = element_text(angle=0, vjust = 0.5, hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHighlighting\n\n\n\n\n\nWe could also use highlighting to do away with noise in a line graph. Then we can create two geom_line layers and highlight just the one in the facet.\n\ntmp &lt;- regional_rates %&gt;%\n  mutate(region2=region)\n\ntmp %&gt;%\n  ggplot(aes(x=Year, y=avg_rate)) +\n  geom_line(data=tmp %&gt;% dplyr::select(-region), aes(group=region2), color=\"grey\", linewidth=0.5, alpha=0.5) +\n  geom_line(aes(color=region), color=\"#69b3a2\", linewidth=1.2 ) +\n  scale_x_continuous(breaks = seq(from=1900, to=2000, by=10)) +\n theme_minimal() +\n  theme(\n    legend.position=\"none\",\n    plot.title = element_text(size=14),\n    panel.grid = element_blank()\n  ) +\n  ggtitle(\"A comparison of measles cases by Region\") +\n  facet_wrap(~region, ncol = 2)"
  },
  {
    "objectID": "03-DataVisualization.html#maps",
    "href": "03-DataVisualization.html#maps",
    "title": "Data Visualization with ggplot2",
    "section": "Maps",
    "text": "Maps\nWhile we were successful at creating a bar chart to compare measles rates in each state, it is often more helpful to use a map to visualize geographic data. There are multiple types of map-based visualizations in R and tools for creating them. While it is possible to make interactive and animated maps in R, in this lesson, we will only cover static maps.\nIn this lesson, we will focus on creating choropleths. Despite the funny name, this is a visualization you have likely seen many many times. A choropleth is a map that links geographic areas or boundaries to some numeric variable.\nggplot2 needs a little help to make map visualizations. Depending on the geographies you want to map, you may need to find geoJSON or shapefiles. There are also several packages in R that come pre-loaded with background maps of common geographies. We’ll be using one in this lesson called usmap. There are several advantages to this package:\n\nIt contains maps of the US with both state and county boundaries.\nYou can create maps based on census regions and divisions. 3. Alaska and Hawaii are included, while many map packages only have a map of the continental US.\nIt creates the map as a ggplot2 object, so you can customize the visualization with ggplot2 functions (i.e. the things you’ve been learning in this lesson!)\n\nWe’ve installed usmap in your RStudio Cloud project, so now let’s load it into our session.\n\nlibrary(usmap)\n\nThe main function in this package is plot_usmap. When you call it without any arguments, you get the background map of the US.\n\nplot_usmap()\n\n\n\n\n\n\n\n\nBy default it shows state boundaries, but we could also ask it to show county boundaries\n\nplot_usmap(regions=\"counties\")\n\n\n\n\n\n\n\n\nSince we do not have that level of data in our dataset, we’ll use the default option. There are two required arguments to plot_usmap().\n\nThe first is a data frame specified with the data argument. This data frame must have a column called state or fips which contains state names or FIPS (Federal Information Processing) codes. FIPS codes must be used for county level data. This data frame must also have a column of values for each state or FIPS.\nThe second argument is the name of the column that contains the values, specified by the value argument.\n\nLet’s first create a data frame with just our 1963 data.\n\nmeasles1963df &lt;- yearly_rates_joined %&gt;% \n  filter(Year==1963)\n\nNow let’s plot our data with plot_usmap(). Remember it’s important to use rate here rather than our raw count numbers since we are dealing with areas of vastly different populations.\n\nplot_usmap(data=measles1963df, values = \"epi_rate\")\n\n\n\n\n\n\n\n\nLet’s try with our viridis color palette.\n\nplot_usmap(data=measles1963df, values = \"epi_rate\") +\n  scale_fill_viridis()\n\n\n\n\n\n\n\n\nNote how the brighter areas seem to highlight the areas of greater concern.\nIf you prefer the darker colors to represent higher rates, and lighter to represent lower, we can switch the direction of the palette with the direction argument.\n\nplot_usmap(data=measles1963df, values = \"epi_rate\") +\n  scale_fill_viridis(direction = -1)\n\n\n\n\n\n\n\n\nLet’s try another of the viridis palettes.\n\nplot_usmap(data=measles1963df, values = \"epi_rate\") +\n  scale_fill_viridis(option = \"rocket\", direction = -1) \n\n\n\n\n\n\n\n\nLet’s add a title, assign to an object, and save to a png file.\n\nmap_1963 &lt;- plot_usmap(data=measles1963df, values = \"epi_rate\") +\n  scale_fill_viridis(option = \"rocket\", direction = -1) + \n  labs(title = \"Incidence Rate of Measles per 100,000 people in 1963\")\n\nggsave(filename = \"figures/map_1963.png\", plot = map_1963, bg = \"white\")"
  },
  {
    "objectID": "03-DataVisualization.html#next-steps-from-beginnr-to-practitionr",
    "href": "03-DataVisualization.html#next-steps-from-beginnr-to-practitionr",
    "title": "Data Visualization with ggplot2",
    "section": "Next Steps: From BeginnR to PractitionR",
    "text": "Next Steps: From BeginnR to PractitionR\nI hope you enjoyed this very brief introduction to R. You may be wondering - where do you go from here?\nThere are tons of R classes and tutorials on the internet, but the best way to learn R is to use it! I recommend picking a data set and just playing around. There’s no harm in making mistakes along the way. It’s much easier to find a useful tutorial if you look for ones that teach a specific task you want to accomplish.\nAlso, check out these helpful resources:\n\nR for Data Science, by Hadley Wickham\nTidyverse documentation\nR Graph Gallery\nR Graphics Cookbook"
  },
  {
    "objectID": "03-DataVisualization.html#footnotes",
    "href": "03-DataVisualization.html#footnotes",
    "title": "Data Visualization with ggplot2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSlides created by the Visualizing the Future project, made possible in part by the Institute of Museum and Library Services, RE-73-18-0059-18.↩︎"
  }
]